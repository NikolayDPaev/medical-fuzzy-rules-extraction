{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_data import get_data_from_directory\n",
    "from preprocessing import preprocess\n",
    "from takagi_sugeno_fnn import TS_FNN\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(get_data_from_directory('./decoded'))\n",
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4037"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathology_diagnoses = ['H25', 'H26', 'H40']\n",
    "\n",
    "for d in data:\n",
    "    d['pathology'] = 1 \\\n",
    "        if any(d['main_diag'].startswith(p_d) for p_d in pathology_diagnoses) or \\\n",
    "           any(any(diag.startswith(p_d) for p_d in pathology_diagnoses) for diag in d['diag']) else 0\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "test_split = 0.1\n",
    "split_index = int(test_split * len(data))\n",
    "test_data, train_data = data[:split_index], data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>main_diag</th>\n",
       "      <th>diag</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>age</th>\n",
       "      <th>right_native</th>\n",
       "      <th>correction_right_sphere</th>\n",
       "      <th>correction_right_cylinder</th>\n",
       "      <th>corrected_right</th>\n",
       "      <th>left_native</th>\n",
       "      <th>correction_left_sphere</th>\n",
       "      <th>correction_left_cylinder</th>\n",
       "      <th>corrected_left</th>\n",
       "      <th>pathology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>H25.0</td>\n",
       "      <td>[Z96.1]</td>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>H52.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>H10.2</td>\n",
       "      <td>[H52.4]</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "      <td>H35.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>H16.8</td>\n",
       "      <td>[H52.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m</td>\n",
       "      <td>T15.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f</td>\n",
       "      <td>H52.2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m</td>\n",
       "      <td>H10.5</td>\n",
       "      <td>[H52.4, H52.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>m</td>\n",
       "      <td>H16.8</td>\n",
       "      <td>[Z03.9, H17.8]</td>\n",
       "      <td>False</td>\n",
       "      <td>62</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m</td>\n",
       "      <td>T15.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>m</td>\n",
       "      <td>S05.1</td>\n",
       "      <td>[H52.0]</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>m</td>\n",
       "      <td>H25.1</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>69</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m</td>\n",
       "      <td>T15.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f</td>\n",
       "      <td>H25.1</td>\n",
       "      <td>[H34.8]</td>\n",
       "      <td>False</td>\n",
       "      <td>82</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>m</td>\n",
       "      <td>H35.8</td>\n",
       "      <td>[H25.0, H35.0]</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>f</td>\n",
       "      <td>H43.3</td>\n",
       "      <td>[H25.0]</td>\n",
       "      <td>False</td>\n",
       "      <td>65</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f</td>\n",
       "      <td>H11.1</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f</td>\n",
       "      <td>H35.0</td>\n",
       "      <td>[H52.4]</td>\n",
       "      <td>False</td>\n",
       "      <td>66</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>m</td>\n",
       "      <td>H00.1</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f</td>\n",
       "      <td>H35.0</td>\n",
       "      <td>[H52.4]</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex main_diag            diag  diabetes  age  right_native  \\\n",
       "0    f     H25.0         [Z96.1]     False   74           0.2   \n",
       "1    f     H52.0              []     False    9           0.7   \n",
       "2    f     H10.2         [H52.4]     False   67           0.7   \n",
       "3    m     H35.0              []     False   60           0.1   \n",
       "4    m     H16.8         [H52.2]     False   59           1.0   \n",
       "5    m     T15.0              []     False   29           1.0   \n",
       "6    f     H52.2              []     False   27           1.0   \n",
       "7    m     H10.5  [H52.4, H52.2]     False   50           0.8   \n",
       "8    m     H16.8  [Z03.9, H17.8]     False   62           0.5   \n",
       "9    m     T15.0              []     False   29           1.0   \n",
       "10   m     S05.1         [H52.0]     False   67           0.4   \n",
       "11   m     H25.1              []      True   69           0.5   \n",
       "12   m     T15.0              []     False   20           0.8   \n",
       "13   f     H25.1         [H34.8]     False   82           0.1   \n",
       "14   m     H35.8  [H25.0, H35.0]     False   61           0.1   \n",
       "15   f     H43.3         [H25.0]     False   65           0.5   \n",
       "16   f     H11.1              []     False   36           0.5   \n",
       "17   f     H35.0         [H52.4]     False   66           0.9   \n",
       "18   m     H00.1              []     False   36           1.0   \n",
       "19   f     H35.0         [H52.4]      True   62           1.0   \n",
       "\n",
       "    correction_right_sphere  correction_right_cylinder  corrected_right  \\\n",
       "0                      0.00                       0.00              0.2   \n",
       "1                      0.75                       0.00              1.0   \n",
       "2                      0.75                       0.00              1.0   \n",
       "3                     -1.25                       0.00              1.0   \n",
       "4                      0.00                       0.00              1.0   \n",
       "5                      0.00                       0.00              1.0   \n",
       "6                      0.00                       0.00              1.0   \n",
       "7                      0.00                       0.50              1.0   \n",
       "8                      0.25                      -3.00              1.0   \n",
       "9                      0.00                       0.00              1.0   \n",
       "10                     0.75                       0.00              1.0   \n",
       "11                     0.00                       0.00              0.5   \n",
       "12                    -0.50                       0.00              1.0   \n",
       "13                     0.00                       0.75              0.2   \n",
       "14                     0.00                       0.00              0.1   \n",
       "15                     0.75                       0.00              1.0   \n",
       "16                     0.00                       0.00              0.5   \n",
       "17                     0.50                       0.00              1.0   \n",
       "18                     0.00                       0.00              1.0   \n",
       "19                     0.00                       0.00              1.0   \n",
       "\n",
       "    left_native  correction_left_sphere  correction_left_cylinder  \\\n",
       "0           0.5                    0.00                      0.75   \n",
       "1           0.8                    0.50                      0.00   \n",
       "2           0.4                    0.00                      0.00   \n",
       "3           1.0                    0.00                      0.00   \n",
       "4           0.7                    0.00                     -0.75   \n",
       "5           1.0                    0.00                      0.00   \n",
       "6           0.1                    0.00                      0.00   \n",
       "7           0.8                    0.00                     -0.75   \n",
       "8           0.8                    0.25                     -0.75   \n",
       "9           1.0                    0.00                      0.00   \n",
       "10          0.9                    0.50                      0.00   \n",
       "11          0.0                   -2.00                      0.00   \n",
       "12          1.0                    0.00                      0.00   \n",
       "13          0.5                    0.50                      1.00   \n",
       "14          0.0                    0.00                      0.00   \n",
       "15          1.0                    0.00                      0.00   \n",
       "16          1.0                    0.00                      0.00   \n",
       "17          0.4                    0.75                      0.00   \n",
       "18          1.0                    0.00                      0.00   \n",
       "19          1.0                    0.00                      0.00   \n",
       "\n",
       "    corrected_left  pathology  \n",
       "0              0.7          1  \n",
       "1              1.0          0  \n",
       "2              0.4          0  \n",
       "3              1.0          0  \n",
       "4              1.0          0  \n",
       "5              1.0          0  \n",
       "6              0.1          0  \n",
       "7              1.0          0  \n",
       "8              1.0          0  \n",
       "9              1.0          0  \n",
       "10             1.0          0  \n",
       "11             0.4          1  \n",
       "12             1.0          0  \n",
       "13             0.6          1  \n",
       "14             0.0          1  \n",
       "15             1.0          1  \n",
       "16             1.0          0  \n",
       "17             1.0          0  \n",
       "18             1.0          0  \n",
       "19             1.0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data)\n",
    "dataframe[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def abs_max(a, b):\n",
    "    if abs(a) > abs(b):\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "def vectorize(data):\n",
    "    result = []\n",
    "    for d in data:\n",
    "        age = int(d['age'])\n",
    "\n",
    "        # result.append([age, d['pathology'], abs_max(d['correction_right_sphere'], d['correction_right_cylinder']), d['corrected_right']])\n",
    "        # result.append([age, d['pathology'], abs_max(d['correction_left_sphere'], d['correction_left_cylinder']), d['corrected_left']])\n",
    "        result.append([age, d['pathology'], d['right_native'], d['corrected_right']])\n",
    "        result.append([age, d['pathology'], d['left_native'], d['corrected_left']])\n",
    "    return np.array(result)\n",
    "\n",
    "def normalize(data):\n",
    "    return [[d[0]/100, d[1], d[2], d[3]] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1MUlEQVR4nO3deVhU1f8H8PcwwAz7vssmKoqoKKSCu5hrLpWpuWeWmuZeahva4lb50yy3StPMpHJJzdx3xV3cNRc2EUQBAUFAZs7vD2S+joACDlxg3q/nmafmzJ07nzvAzNtz7rlHJoQQICIiItIjBlIXQERERFTRGICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICqsGPHjuHVV1+Fh4cHFAoFnJycEBwcjEmTJmlt17ZtW7Rt21arTSaTYfr06Zr7v/zyC2QyGU6ePFkBlZfdzJkzsXHjxkLtly5dwvTp0xEdHV3hNVUn4eHhqF+/PkxMTCCTyRAZGVnhNRT8Lj75syzqdzg6OhrdunWDra0tZDIZxo8fDwA4c+YM2rRpAysrK8hkMsyfP7/Cai+tRYsW4ZdffpG6jBfStm1b+Pv7S12GzuTm5mLkyJFwcXGBXC5HQEDAC+1v+vTpkMlkuimuCFu3btX6LKeSM5S6ACqbf/75Bz169EDbtm0xd+5cuLi4ICEhASdPnsTatWvx7bffarZdtGiRhJXq1syZM9G7d2/06tVLq/3SpUuYMWMG2rZtCy8vL0lqq+ru3r2LQYMGoXPnzli0aBEUCgXq1KkjdVkAiv4dnjBhAo4dO4bly5fD2dkZLi4uAIBhw4YhMzMTa9euhY2NTaX+fVi0aBHs7e0xdOhQqUuhxxYvXoylS5di4cKFCAwMhLm5udQlPdPWrVvxww8/MASVAQNQFTV37lx4e3tj+/btMDT834+xX79+mDt3rta2fn5+FV0e6dCjR48gk8m0fs7l4b///sOjR48wcOBAtGnTRif7zMrKgqmp6Qvvp6jf4QsXLqBp06aFwvCFCxfwzjvvoEuXLi/8ugCgUqmQl5cHhUKhk/1R2Tx8+BAmJibl/joXLlyAiYkJxowZU+6vVZnp6m+3MuMQWBWVnJwMe3v7Ir8UDQy0f6xFDR8UJyMjA6NGjYK9vT3s7Ozw2muv4fbt21rbqNVqzJ07F3Xr1oVCoYCjoyMGDx6MW7duaW3n5eVV5L9si6onPT0dkydPhre3N4yNjeHm5obx48cjMzNTs41MJkNmZiZWrlwJmUwGmUyGtm3b4pdffsEbb7wBAGjXrp3msSeHFnbt2oXQ0FBYWlrC1NQULVq0wO7du5/7fqjVanz55Zfw9fWFiYkJrK2t0bBhQyxYsEBruytXruDNN9+Ek5MTFAoFPDw8MHjwYOTk5Gi2uXDhAnr27AkbGxsolUoEBARg5cqVWvvZt28fZDIZfv31V0yaNAlubm5QKBS4fv16iY/j7t27ePfdd+Hu7g6FQgEHBwe0aNECu3btKvY4hw4dipYtWwIA+vbtq3lvC2zatAnBwcEwNTWFhYUFXn75ZURERGjto6Cr//Tp0+jduzdsbGzg4+PzzPf36NGjaNGiBZRKJVxdXTFt2jQ8evSo0HZP/s4UvEfXr1/Hv//+q/XzlslkyMvLw+LFizXtBRITEzFixAjUqFEDxsbG8Pb2xowZM5CXl6fZJjo6GjKZDHPnzsWXX34Jb29vKBQK7N27FwBw8uRJ9OjRA7a2tlAqlWjcuDH++OMPrVoL6ti7d+8z/5a8vLxw8eJF7N+/X1Pr83qrZDIZxowZg19//RX16tWDqakpGjVqhC1btmhtN3To0CL3VdRwTME+V6xYofk9DwoKwtGjRyGEwNdffw1vb2+Ym5ujffv2mt/Fpx08eBDNmzeHiYkJ3Nzc8Omnn0KlUmltk5ubiy+//FLz2eHg4IC33noLd+/e1drOy8sLr7zyCtavX4/GjRtDqVRixowZAIA///wTzZo1g5WVFUxNTVGzZk0MGzbsme8bAGRnZ2PatGlanzGjR4/G/fv3td6Ln376CQ8fPizyc6Qo27ZtQ2hoqKaeevXqYdasWc98ztOnIDx53E9+ZmZlZWk+F5VKJWxtbREUFITff/8dQP7P+YcfftDss+BWMHwshMCiRYsQEBAAExMT2NjYoHfv3rh586bW6xYMYx44cAAhISEwNTXVvKd79uxB27ZtYWdnBxMTE3h4eOD1119HVlbWM4+xShBUJQ0fPlwAEO+//744evSoyM3NLXbbNm3aiDZt2mi1ARBhYWGa+ytWrBAARM2aNcX7778vtm/fLn766SdhY2Mj2rVrp/Xcd999VwAQY8aMEdu2bRNLliwRDg4Owt3dXdy9e1eznaenpxgyZMhz68nMzBQBAQHC3t5ezJs3T+zatUssWLBAWFlZifbt2wu1Wi2EECIiIkKYmJiIrl27ioiICBERESEuXrwokpKSxMyZMwUA8cMPP2geS0pKEkII8euvvwqZTCZ69eol1q9fLzZv3ixeeeUVIZfLxa5du575Ps+aNUvI5XIRFhYmdu/eLbZt2ybmz58vpk+frtkmMjJSmJubCy8vL7FkyRKxe/dusXr1atGnTx+Rnp4uhBDiypUrwsLCQvj4+IhVq1aJf/75R7z55psCgJgzZ45mX3v37hUAhJubm+jdu7fYtGmT2LJli0hOTi7xcXTq1Ek4ODiIZcuWiX379omNGzeKzz77TKxdu7bY47x+/br44YcfBAAxc+ZMzXsrhBC//fabACA6duwoNm7cKMLDw0VgYKAwNjYWBw8e1OwjLCxMABCenp5iypQpYufOnWLjxo3FvubFixeFqamp8PPzE7///rv4+++/RadOnYSHh4cAIKKiojTbPvk7k5aWJiIiIoSzs7No0aKF5uedmJgoIiIiBADRu3dvTbsQQiQkJAh3d3fh6ekpli5dKnbt2iW++OILoVAoxNChQzWvExUVpXn/27VrJ/766y+xY8cOERUVJfbs2SOMjY1Fq1atRHh4uNi2bZsYOnSoACBWrFih2UdJ/5ZOnz4tatasKRo3bqyp9fTp08W+X0Lk/916eXmJpk2bij/++ENs3bpVtG3bVhgaGoobN25othsyZIjw9PQs9PyCn9HT+/T09BQhISFi/fr1YsOGDaJOnTrC1tZWTJgwQfTs2VNs2bJF/Pbbb8LJyUk0bNhQ8zdZ8LOxs7MTrq6u4rvvvhPbt28XY8eOFQDE6NGjNdupVCrRuXNnYWZmJmbMmCF27twpfvrpJ+Hm5ib8/PxEVlaWZltPT0/h4uIiatasKZYvXy727t0rjh8/Lo4cOSJkMpno16+f2Lp1q9izZ49YsWKFGDRo0DPfN7VaLTp16iQMDQ3Fp59+Knbs2CG++eYbYWZmJho3biyys7OFEPmfMV27dhUmJiaFPkeK8tNPPwmZTCbatm0r1qxZI3bt2iUWLVok3nvvvee+509+/j553E9+Zo4YMUKYmpqKefPmib1794otW7aI2bNni4ULFwoh8v9ue/fuLQBo6o2IiNAczzvvvCOMjIzEpEmTxLZt28SaNWtE3bp1hZOTk0hMTNT6Gdra2gp3d3excOFCsXfvXrF//34RFRUllEqlePnll8XGjRvFvn37xG+//SYGDRokUlNTn/meVwUMQFXUvXv3RMuWLQUAAUAYGRmJkJAQMWvWLJGRkaG1bWkC0JN/uEIIMXfuXAFAJCQkCCGEuHz5cpHbHTt2TAAQH330kaatpAFo1qxZwsDAQJw4cUJru7/++ksAEFu3btW0mZmZFbnPP//8UwAQe/fu1WrPzMwUtra2onv37lrtKpVKNGrUSDRt2rTQvp70yiuviICAgGdu0759e2Ftbf3MD8p+/foJhUIhYmNjtdq7dOkiTE1Nxf3794UQ/wtArVu3LvNxmJubi/Hjxz+z5qIUvPaff/6ptX9XV1fRoEEDoVKpNO0ZGRnC0dFRhISEaNoKPug/++yzEr1e3759hYmJidYHcV5enqhbt+4zA1ABT09P0a1bt0L7ffqLV4j8LxJzc3MRExOj1f7NN98IAJqwVxCAfHx8Cv2jom7duqJx48bi0aNHWu2vvPKKcHFx0bw/Jf1bEkKI+vXrFzquZwEgnJycNMFaCCESExOFgYGBmDVrlqattAHI2dlZPHjwQNO2ceNGAUAEBARohZ358+cLAOLcuXOatjZt2ggA4u+//9ba7zvvvCMMDAw07/nvv/8uAIh169ZpbXfixAkBQCxatEjT5unpKeRyubh69arWtgU/r4K/l5Latm2bACDmzp2r1R4eHi4AiGXLlmnahgwZIszMzJ67z4yMDGFpaSlatmyp9R497UUCkL+/v+jVq9cz6xg9enSh/QshNP8Y+Pbbb7Xa4+LihImJifjwww81bQU/w927d2ttW/AZHBkZ+cwaqioOgVVRdnZ2OHjwIE6cOIHZs2ejZ8+e+O+//zBt2jQ0aNAA9+7dK9N+e/TooXW/YcOGAICYmBgA0AwFPD201bRpU9SrV69Ew0pP27JlC/z9/REQEIC8vDzNrVOnTpDJZNi3b1/pD+SxI0eOICUlBUOGDNHat1qtRufOnXHixAmtYbanNW3aFGfPnsV7772H7du3Iz09XevxrKws7N+/H3369IGDg0Ox+9mzZw9CQ0Ph7u6u1T506FBkZWUVGk56/fXXy3wcTZs2xS+//IIvv/wSR48eLXJIqaSuXr2K27dvY9CgQVpDq+bm5nj99ddx9OjRQl3hT9denL179yI0NBROTk6aNrlcjr59+5a53uJs2bIF7dq1g6urq9b7V3Ce0P79+7W279GjB4yMjDT3r1+/jitXrmDAgAEAoLWPrl27IiEhAVevXi20jyc9/bdUVu3atYOFhYXmvpOTExwdHV9ov+3atYOZmZnmfr169QAAXbp00RoyK2h/+rUsLCwKHW///v2hVqtx4MABAPk/A2tra3Tv3l3r/QsICICzs3Ohv/OGDRsWOgn/pZdeAgD06dMHf/zxB+Lj40t0fHv27AFQ+HPrjTfegJmZWZk+t44cOYL09HS899575TbLq2nTpvj3338xdepU7Nu3Dw8fPizxc7ds2QKZTIaBAwdqvd/Ozs5o1KhRoffbxsYG7du312oLCAiAsbEx3n33XaxcubLQ0FlVxwBUxQUFBWHKlCn4888/cfv2bUyYMAHR0dGFToQuKTs7O637BSd+FvzhJScnA4Bmxs2TXF1dNY+Xxp07d3Du3DkYGRlp3SwsLCCEKHOYK9g3APTu3bvQ/ufMmQMhBFJSUop9/rRp0/DNN9/g6NGj6NKlC+zs7BAaGqq5XEBqaipUKhVq1KjxzDqSk5OLfc8KHn/S09uW5jjCw8MxZMgQ/PTTTwgODoatrS0GDx6MxMTEZ9ZYXN1F1VNQu1qtRmpq6jNrf9a+nZ2dC7UX1fai7ty5g82bNxd67+rXrw8AhX7Hinv/J0+eXGgf7733XpH7eN7fUlk9vd+Cfb/Ifm1tbbXuGxsbP7M9Oztbq/3JEFug4OdY8Dt0584d3L9/H8bGxoXew8TExOf+DACgdevW2LhxI/Ly8jB48GDUqFED/v7+mnNiipOcnAxDQ8NC/0iRyWRwdnYu0+dWwXlLz/vbfxHfffcdpkyZgo0bN6Jdu3awtbVFr169cO3atec+986dOxBCwMnJqdD7ffTo0RK93z4+Pti1axccHR0xevRo+Pj4wMfHp9A5kFUVZ4FVI0ZGRggLC8P//d//4cKFC+XyGgUfvgkJCYX+8G/fvg17e3vNfaVSqXUScIF79+5pbWdvbw8TExMsX768yNd8ctvSKnjuwoUL0bx58yK3KerDu4ChoSEmTpyIiRMn4v79+9i1axc++ugjdOrUCXFxcbC1tYVcLi90AvjT7OzskJCQUKi94KTYp4/x6X9RluY47O3tMX/+fMyfPx+xsbHYtGkTpk6diqSkJGzbtu2ZdRZVN4BiazcwMICNjc0za3/WvosKZWUJas9jb2+Phg0b4quvviry8YIgWqC493/atGl47bXXityHr6+vDirVjWf97ZWHgoD4pIKfY8HvUMHJ4MX9Dj7ZqwUU/3vUs2dP9OzZEzk5OTh69ChmzZqF/v37w8vLC8HBwUU+x87ODnl5ebh7965WCBJCIDExUdOzVBoF+3ne335RFApFkT+fp4OYmZkZZsyYgRkzZuDOnTua3qDu3bvjypUrz3wNe3t7yGQyHDx4sMgZjE+3Ffd+t2rVCq1atYJKpcLJkyexcOFCjB8/Hk5OTujXr9/zDrVSYwCqohISEopM7JcvXwZQ+ANdVwq6SFevXq31oXHixAlcvnwZH3/8sabNy8sL586d03r+f//9h6tXr2p94b/yyiuYOXMm7Ozs4O3t/czXL+5fusX967pFixawtrbGpUuXXnhaq7W1NXr37o34+HiMHz8e0dHR8PPzQ5s2bfDnn3/iq6++KjashYaGYsOGDbh9+7bWz2bVqlUwNTUtNtS86HF4eHhgzJgx2L17Nw4fPlzi5xXw9fWFm5sb1qxZg8mTJ2s+JDMzM7Fu3TrNzLCyaNeuHTZt2oQ7d+5owptKpUJ4eHiZ9vcsr7zyCrZu3QofH59Cga0kfH19Ubt2bZw9exYzZ87UWV0v2nNTHC8vLyQlJWm9t7m5udi+fbvOXwvInz26adMmrWGwNWvWwMDAAK1btwaQ/zNYu3YtVCoVmjVr9sKvqVAo0KZNG1hbW2P79u04c+ZMsQEoNDQUc+fOxerVqzFhwgRN+7p165CZmYnQ0NBSv35ISAisrKywZMkS9OvXr1TDYEV9Nu7ZswcPHjwo9jlOTk4YOnQozp49i/nz52umqT/52ffkZQJeeeUVzJ49G/Hx8ejTp08pj64wuVyOZs2aoW7duvjtt99w+vRpBiCSRqdOnVCjRg10794ddevWhVqtRmRkJL799luYm5tj3Lhx5fK6vr6+ePfdd7Fw4UIYGBigS5cuiI6Oxqeffgp3d3etD5dBgwZh4MCBeO+99/D6668jJiYGc+fOLdQNPX78eKxbtw6tW7fGhAkT0LBhQ6jVasTGxmLHjh2YNGmS5gOzQYMG2LdvHzZv3gwXFxdYWFjA19dXcyXaZcuWwcLCAkqlEt7e3rCzs8PChQsxZMgQpKSkoHfv3nB0dMTdu3dx9uxZ3L17F4sXLy72eLt37w5/f38EBQXBwcEBMTExmD9/Pjw9PVG7dm0AwLx589CyZUs0a9YMU6dORa1atXDnzh1s2rQJS5cuhYWFBcLCwjTnoXz22WewtbXFb7/9hn/++Qdz586FlZXVM993c3PzEh1HWloa2rVrh/79+6Nu3bqwsLDAiRMnsG3btmJ7Lp7FwMAAc+fOxYABA/DKK69gxIgRyMnJwddff4379+9j9uzZpd5ngU8++QSbNm1C+/bt8dlnn8HU1BQ//PDDM8/JKqvPP/8cO3fuREhICMaOHQtfX19kZ2cjOjoaW7duxZIlS547lLF06VJ06dIFnTp1wtChQ+Hm5oaUlBRcvnwZp0+fxp9//lnquho0aIC1a9ciPDwcNWvWhFKpRIMGDcp6mBp9+/bFZ599hn79+uGDDz5AdnY2vvvuu0LT0nXFzs4Oo0aNQmxsLOrUqYOtW7fixx9/xKhRo+Dh4QEg/xplv/32G7p27Ypx48ahadOmMDIywq1bt7B371707NkTr7766jNf57PPPsOtW7cQGhqKGjVq4P79+1iwYAGMjIyeee2ql19+GZ06dcKUKVOQnp6OFi1a4Ny5cwgLC0Pjxo0xaNCgUh+zubk5vv32WwwfPhwdOnTAO++8AycnJ1y/fh1nz57F999/X+xzBw0ahE8//RSfffYZ2rRpg0uXLuH7778v9DnQrFkzvPLKK2jYsCFsbGxw+fJl/Prrr1r/8Cj4fZkzZw66dOkCuVyOhg0bokWLFnj33Xfx1ltv4eTJk2jdujXMzMyQkJCAQ4cOoUGDBhg1atQzj3HJkiXYs2cPunXrBg8PD2RnZ2t66jt06FDq96zSkfQUbCqz8PBw0b9/f1G7dm1hbm4ujIyMhIeHhxg0aJC4dOmS1ralmQX29EysgplBT86uUqlUYs6cOaJOnTrCyMhI2Nvbi4EDB4q4uDit56rVajF37lxRs2ZNoVQqRVBQkNizZ0+R9Tx48EB88sknwtfXVxgbGwsrKyvRoEEDMWHCBK1ZQpGRkaJFixbC1NRUANDaz/z584W3t7eQy+WFpibv379fdOvWTdja2gojIyPh5uYmunXrpjXjqSjffvutCAkJEfb29sLY2Fh4eHiIt99+W0RHR2ttd+nSJfHGG28IOzs7zXZDhw7VTEcVQojz58+L7t27CysrK2FsbCwaNWqkVeOT73dxdT3vOLKzs8XIkSNFw4YNhaWlpTAxMRG+vr4iLCxMZGZmPvNYn/XaGzduFM2aNRNKpVKYmZmJ0NBQcfjwYa1tCma7PHkphOc5fPiwaN68uVAoFMLZ2Vl88MEHYtmyZTqfBSaEEHfv3hVjx44V3t7ewsjISNja2orAwEDx8ccfa2ZAFcwC+/rrr4us9+zZs6JPnz7C0dFRGBkZCWdnZ9G+fXuxZMkSzTal+VuKjo4WHTt2FBYWFprp6M9S3LEVNeNy69atIiAgQJiYmIiaNWuK77//vtgZSU/vs7j3oajfkTZt2oj69euLffv2iaCgIKFQKISLi4v46KOPCs2Ye/Tokfjmm29Eo0aNhFKpFObm5qJu3bpixIgR4tq1a1rHU9TPdsuWLaJLly7Czc1NGBsbC0dHR9G1a1etyzEU5+HDh2LKlCnC09NTGBkZCRcXFzFq1KhC07lLOguswNatW0WbNm2EmZmZ5rIOT17aoqj3PCcnR3z44YfC3d1dmJiYiDZt2ojIyMhCP8epU6eKoKAgYWNjIxQKhahZs6aYMGGCuHfvnta+hg8fLhwcHIRMJiv0t7N8+XLRrFkzYWZmJkxMTISPj48YPHiwOHnypGabgp/h0yIiIsSrr74qPD09hUKhEHZ2dqJNmzZi06ZNJX5/KjOZEEJUaOIiIiIikhhngREREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7vBBiEdRqNW7fvg0LC4tyW+SOiIiIdEsIgYyMDLi6umot4FwUBqAi3L59u9Cq3URERFQ1xMXFPffq7gxARShYlC8uLg6WlpYSV0NEREQlkZ6eDnd390KL6xaFAagIBcNelpaWDEBERERVTElOX+FJ0ERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3eCXoCqRSCxyPSkFSRjYcLZRo6m0LuQEXWyUiIqpoDEAVZNuFBMzYfAkJadmaNhcrJcK6+6Gzv4uElREREekfDoFVgG0XEjBq9Wmt8AMAiWnZGLX6NLZdSJCoMiIiIv3EAFTOVGqBGZsvQRTxWEHbjM2XoFIXtQURERGVBwagcnY8KqVQz8+TBICEtGwcj0qpuKKIiIj0HANQOUvKKD78lGU7IiIienEMQOXM0UKp0+2IiIjoxTEAlbOm3rZwsVLiWZPd5QYyWCg5IY+IiKiiMACVM7mBDGHd/QCg2BCkUgu8vvgI1hyLhRA8GZqIiKi8MQBVgM7+Llg8sAmcrbSHuVyslPi6d0O0r+uInDw1PtpwHmPXRiIj+5FElRIREekHmWCXQyHp6emwsrJCWloaLC0tdbbf4q4ErVYL/HToJuZuu4o8tYCXnSm+798E/m5WOnttIiKi6q40398MQEUorwD0PKdiUjH29zOIv/8QxoYG+LRbPQxs7gmZjMtlEBERPU9pvr85BFaJBHra4J+xLdGhnhNy89T49O+LGL3mNNI5JEZERKRTDECVjLWpMX4cHIhPutWDkVyGrecT8cp3h3Du1n2pSyMiIqo2GIAqIZlMhuGtauLPkSGoYWOC2JQsvL74CFYcjuIsMSIiIh1gAKrEAtyt8c/YVuhc3xmPVPlrio1cfQppWRwSIyIiehEMQJWclYkRFg9sghk96sNYboDtF++g28KDOBObKnVpREREVRYDUBUgk8kwJMQL60aFwNPOFLdSH+KNJRH46eBNDokRERGVAQNQFdKghhU2v98S3Rq6IE8t8OU/l/HOqpO4n5UrdWlERERVCgNQFWOpNML3bzbGl738YWxogF2Xk9B1wUGcikmRujQiIqIqgwGoCpLJZBjY3BMb3guBt70Zbqdlo8/So1iy/wbUag6JERERPQ8DUBVW3zV/SKxngCtUaoHZ/17BsJUnkJLJITEiIqJnYQCq4swVhpjfNwCzX2sAhaEB9l29i64LDuJ4FIfEiIiIisMAVA3IZDL0a+qBv8e0gI+DGRLTs9FvWQS+33ONQ2JERERFYACqRuo6W2LTmJZ4rYkb1AL4Zsd/GLLiOO49yJG6NCIiokqFAaiaMVMYYl6fAHzduyGURgY4eO0eui44iIgbyVKXRkREVGkwAFVTbwS5Y/OYlqjtaI6kjBwM+OkoFuy6BhWHxIiIiBiAqrPaThbYNKYl+gTVgFoA/7frPwz6+RiSMrKlLo2IiEhSDEDVnImxHHN7N8K8Po1gaizHkRvJ6LrgIA5duyd1aURERJJhANITrzWpgU1jWqKuswXuPcjFoOXH8O2Oq8hTqaUujYiIqMIxAOmRWo7m2Di6Bd5s6gEhgIV7rqP/T8dwJ51DYkREpF8YgPSM0kiOWa81wHdvNoaZsRzHo1LQZcFB7P/vrtSlERERVRgGID3Vo5ErtoxtBT8XS6Rk5mLI8uOYs+0Kh8SIiEgvMADpMW97M6x/LwSDmnsCABbvu4F+y47i9v2HEldGRERUvhiA9JzSSI4vevnjh/5NYKEwxMmYVHT97iD2XLkjdWlERETlhgGIAADdGrpgy9iWaOBmhftZjzDsl5OYufUyHnFIjIiIqiEGINLwtDPDX6OCMTTECwCw7MBN9FkagVupWdIWRkREpGMMQKRFYSjH9B71sWRgICyVhjgTex/dvjuEHRcTpS6NiIhIZxiAqEid/Z3xz9hWaORujbSHj/Dur6fw+eZLyM3jkBgREVV9DEBULHdbU/w5IhjDW3oDAJYfjsIbS44gLoVDYkREVLUxANEzGRsa4JNX/PDT4CBYmRjh7K00dP3uILZdSJC6NCIiojJjAKIS6eDnhK3jWqGJhzUysvMwcvVphP19ATl5KqlLIyIiKjUGICoxN2sThI8Ixog2NQEAKyNi8PriI4i+lwkAUKkFIm4k4+/IeETcSIZKLaQsl4iIqFgyIQS/pZ6Snp4OKysrpKWlwdLSUupyKqW9V5Iw8Y9IpGY9grnCEP2auuOfcwlISPvfwqouVkqEdfdDZ38XCSslIiJ9UZrvbwagIjAAlUxC2kOM/f0MTkSnFvm47PF/Fw9swhBERETlrjTf3xwCozJzsTLB6rebwUwhL/LxgmQ9Y/MlDocREVGlwgBEL+R07H1k5hR/IrQAkJCWjeNRKRVXFBER0XMwANELScrIfv5GpdiOiIioIjAA0QtxtFDqdDsiIqKKwABEL6Spty1crJSaE56fJkP+bLCm3rYVWRYREdEzMQDRC5EbyBDW3Q8Aig1BYd39IDco7lEiIqKKxwBEL6yzvwsWD2wCZ6vCw1yTOtbhFHgiIqp0JA9AixYtgre3N5RKJQIDA3Hw4MFit923bx9kMlmh25UrV4rcfu3atZDJZOjVq1c5VU8FOvu74NCU9vj9neZY0C8A7eo4AACuJGZIXBkREVFhhlK+eHh4OMaPH49FixahRYsWWLp0Kbp06YJLly7Bw8Oj2OddvXpV6wJHDg4OhbaJiYnB5MmT0apVq3KpnQqTG8gQ7GMHAKjlaI69/93FtguJuJOeDSdLngRNRESVh6Q9QPPmzcPbb7+N4cOHo169epg/fz7c3d2xePHiZz7P0dERzs7Omptcrn0hPpVKhQEDBmDGjBmoWbNmeR4CFaO+qxVe8rJBnlpgzbFYqcshIiLSIlkAys3NxalTp9CxY0et9o4dO+LIkSPPfG7jxo3h4uKC0NBQ7N27t9Djn3/+ORwcHPD222/rtGYqncHBXgCANcdjkZunlrYYIiKiJ0g2BHbv3j2oVCo4OTlptTs5OSExMbHI57i4uGDZsmUIDAxETk4Ofv31V4SGhmLfvn1o3bo1AODw4cP4+eefERkZWeJacnJykJOTo7mfnp5e+gOiQjr7O8PRQoGkjBz8eyEBPQPcpC6JiIgIgMTnAAGATKY9PVoIUaitgK+vL3x9fTX3g4ODERcXh2+++QatW7dGRkYGBg4ciB9//BH29vYlrmHWrFmYMWNG2Q6AimUkN8CAZp74v13/YVVEDAMQERFVGpINgdnb20Mulxfq7UlKSirUK/QszZs3x7Vr1wAAN27cQHR0NLp37w5DQ0MYGhpi1apV2LRpEwwNDXHjxo0i9zFt2jSkpaVpbnFxcWU/MNLyZjN3GMllOBWTigvxaVKXQ0REBEDCAGRsbIzAwEDs3LlTq33nzp0ICQkp8X7OnDkDF5f868zUrVsX58+fR2RkpObWo0cPtGvXDpGRkXB3dy9yHwqFApaWllo30g1HCyW6PL4O0Moj0dIWQ0RE9JikQ2ATJ07EoEGDEBQUhODgYCxbtgyxsbEYOXIkgPyemfj4eKxatQoAMH/+fHh5eaF+/frIzc3F6tWrsW7dOqxbtw4AoFQq4e/vr/Ua1tbWAFConSrOkBAvbDp7G3+fvY2PutaDjZmx1CUREZGekzQA9e3bF8nJyfj888+RkJAAf39/bN26FZ6engCAhIQExMb+bwp1bm4uJk+ejPj4eJiYmKB+/fr4559/0LVrV6kOgUqgiYc1/N0scSE+HeEn4zCyjY/UJRERkZ6TCSGE1EVUNunp6bCyskJaWhqHw3Tkj5Nx+PCvc3CzNsGBD9txbTAiItK50nx/S74UBumHHo1cYWNqhPj7D7H78h2pyyEiIj3HAEQVQmkkR9+X8pc3WRURI3E1RESk7xiAqMIMaOYBAxlw6Po9XE/iIqlERCQdBiCqMO62pgitl3+NJ/YCERGRlBiAqEINDfECAKw7dQsZ2Y+kLYaIiPQWAxBVqBAfO/g4mCEzV4X1p+OlLoeIiPQUAxBVKJlMhiGPe4FWRkRDreZVGIiIqOIxAFGFe61JDZgrDHHzbiYO37gndTlERKSHGICowpkrDNE7sAYAYOURngxNREQVjwGIJDGwef5yJ7uv3EFcSpbE1RARkb5hACJJ1HI0R6va9hACWH2UvUBERFSxGIBIMkOCvQAAa0/E4WGuStpiiIhIrzAAkWTa1XVEDRsTpD18hM1nb0tdDhER6REGIJKM3ECGQY/PBfrlSDSE4JR4IiKqGAxAJKm+L7lDYWiASwnpOBWTKnU5RESkJxiASFLWpsboFeAGAFjJ9cGIiKiCMACR5AYF5w+D/Xs+AUnp2RJXQ0RE+oABiCTn72aFIE8b5KkFfjsWK3U5RESkBxiAqFIoWB9szfFY5OappS2GiIiqPQYgqhQ61XeGo4UCdzNysO1iotTlEBFRNccARJWCsaEB+jfzAACsPBItbTFERFTtMQBRpdG/mQeM5DKciknFhfg0qcshIqJqjAGIKg1HCyW6+LsAAFZFREtbDBERVWsMQFSpDAnJnxL/d+RtpGbmSlwNERFVVwxAVKk08bBBfVdL5OSpEX4yTupyiIiommIAokpFJpNppsT/GhEDlZrrgxERke4xAFGl06ORK6xNjRB//yH2XEmSuhwiIqqGGICo0lEaydH3JXcAnBJPRETlgwGIKqWBzTxhIAMOXb+H60kZUpdDRETVDAMQVUrutqYIrecEIP9cICIiIl1iAKJKa0iwFwDgr1O3kJH9SNpiiIioWmEAokqrRS07+DiYITNXhfWn46Uuh4iIqhEGIKq0npwSvzIiGkJwSjwREekGAxBVaq81qQFzhSFu3s3E4evJUpdDRETVBAMQVWrmCkO83sQNAPALp8QTEZGOMABRpTfo8cnQu6/cQVxKlrTFEBFRtcAARJVeLUdztKptDyGA1cc4JZ6IiF4cAxBVCYMf9wKFn4hD9iOVtMUQEVGVxwBEVUL7uo6oYWOC+1mPsCnyttTlEBFRFccARFWC3ECGQc09AeSfDM0p8URE9CIYgKjK6BPkDoWhAS4lpON0bKrU5RARURXGAERVho2ZMXoGuAIAfjnCk6GJiKjsGICoSik4Gfrf8wlISs+WthgiIqqyGICoSvF3s0KQpw3y1AJrjsdKXQ4REVVRDEBU5Qx+vD7Yb8dikZunlrYYIiKqkhiAqMrpXN8ZjhYK3M3IwbaLiVKXQ0REVRADEFU5xoYG6N/MAwCwiuuDERFRGTAAUZXUv6kHDA1kOBmTigvxaVKXQ0REVQwDEFVJjpZKdGngAgBYFREtbTFERFTlMABRlTU0JP/K0H9H3kZqZq7E1RARUVXCAERVVhMPG9R3tUROnhp/nIyTuhwiIqpCGICoypLJZBjy+MKIvx6NgUrN9cGIiKhkGICoSusR4AprUyPcSn2IPVeSpC6HiIiqCAYgqtKURnL0fckdAE+GJiKikmMAoipvYDNPyGTAwWv3cD3pgdTlEBFRFVCmAJSXl4ddu3Zh6dKlyMjIAADcvn0bDx7wy4cqnrutKULrOgEAfmUvEBERlUCpA1BMTAwaNGiAnj17YvTo0bh79y4AYO7cuZg8ebLOCyQqiaGP1wf769QtZGQ/krYYIiKq9EodgMaNG4egoCCkpqbCxMRE0/7qq69i9+7dOi2OqKRa1LJDTQczZOaqsOFMvNTlEBFRJVfqAHTo0CF88sknMDY21mr39PREfDy/eEgaT06JX3kkGkJwSjwRERWv1AFIrVZDpVIVar916xYsLCx0UhRRWbweWAPmCkPcuJuJw9eTpS6HiIgqsVIHoJdffhnz58/X3JfJZHjw4AHCwsLQtWvXUhewaNEieHt7Q6lUIjAwEAcPHix223379kEmkxW6XblyRbPNjz/+iFatWsHGxgY2Njbo0KEDjh8/Xuq6qOoxVxji9SZuAICVPBmaiIieodQBaN68edi/fz/8/PyQnZ2N/v37w8vLC/Hx8ZgzZ06p9hUeHo7x48fj448/xpkzZ9CqVSt06dIFsbGxz3ze1atXkZCQoLnVrl1b89i+ffvw5ptvYu/evYiIiICHhwc6duzI4Tk9MejxMNjuy3cQl5IlbTFERFRpyUQZTpZ4+PAh1q5di1OnTkGtVqNJkyYYMGCA1knRJdGsWTM0adIEixcv1rTVq1cPvXr1wqxZswptv2/fPrRr1w6pqamwtrYu0WuoVCrY2Njg+++/x+DBg0v0nPT0dFhZWSEtLQ2WlpYleg5VHgN/OoZD1+9hRJuamNalntTlEBFRBSnN93epeoAePXqEmjVrIioqCm+99Ra+//57LFq0CMOHDy91+MnNzcWpU6fQsWNHrfaOHTviyJEjz3xu48aN4eLigtDQUOzdu/eZ22ZlZeHRo0ewtbUtdpucnBykp6dr3ajqGvJ4Snz4iThkPyp8vhoREVGpApCRkRFycnIgk8le+IXv3bsHlUoFJycnrXYnJyckJiYW+RwXFxcsW7YM69atw/r16+Hr64vQ0FAcOHCg2NeZOnUq3Nzc0KFDh2K3mTVrFqysrDQ3d3f3sh0UVQrt6zrCzdoE97MeYdPZ21KXQ0RElVCpzwF6//33MWfOHOTl5emkgKfDlBCi2IDl6+uLd955B02aNEFwcDAWLVqEbt264Ztvvily+7lz5+L333/H+vXroVQqi61h2rRpSEtL09zi4uLKfkAkObmBDIOCPQFwSjwRERXNsLRPOHbsGHbv3o0dO3agQYMGMDMz03p8/fr1JdqPvb095HJ5od6epKSkQr1Cz9K8eXOsXr26UPs333yDmTNnYteuXWjYsOEz96FQKKBQKEr8mlT59Q1yx//t/A8Xb6fjdGwqAj2LHwIlIiL9U+oeIGtra7z++uvo1KkTXF1dtYaOrKysSrwfY2NjBAYGYufOnVrtO3fuREhISIn3c+bMGbi4uGi1ff311/jiiy+wbds2BAUFlXhfVH3YmBmjZ4ArAGDlkRiJqyEiosqm1D1AK1as0NmLT5w4EYMGDUJQUBCCg4OxbNkyxMbGYuTIkQDyh6bi4+OxatUqAMD8+fPh5eWF+vXrIzc3F6tXr8a6deuwbt06zT7nzp2LTz/9FGvWrIGXl5emh8nc3Bzm5uY6q50qv8HBXvjj5C1sPZ+AT7rVg6Nl8cOgRESkX0odgArcvXsXV69ehUwmQ506deDg4FDqffTt2xfJycn4/PPPkZCQAH9/f2zduhWenvnnbyQkJGhdEyg3NxeTJ09GfHw8TExMUL9+ffzzzz9aF2BctGgRcnNz0bt3b63XCgsLw/Tp08t2sFQl+btZIdDTBqdiUrHmeCzGd6gjdUlERFRJlPo6QJmZmXj//fexatUqqNVqAIBcLsfgwYOxcOFCmJqalkuhFYnXAao+Np29jbG/n4GDhQKHp7SHsWGpR32JiKiKKLfrAAH5w1b79+/H5s2bcf/+fdy/fx9///039u/fj0mTJpW5aKLy0Lm+MxwsFLibkYPtF4u+vAIREemfUgegdevW4eeff0aXLl1gaWkJS0tLdO3aFT/++CP++uuv8qiRqMyMDQ3Qv6kHgPwp8UREREAZAlBWVlaR09QdHR2RlcW1l6jyGdDMA4YGMpyMScWF+DSpyyEiokqg1AEoODgYYWFhyM7O1rQ9fPgQM2bMQHBwsE6LI9IFR0slujTIv1TCrxGcEk9ERGWYBbZgwQJ07twZNWrUQKNGjSCTyRAZGQmlUont27eXR41EL2xIsCc2n72NjZHxmNa1LqxNjaUuiYiIJFTqAOTv749r165h9erVuHLlCoQQ6NevX5lWgyeqKIGeNvBzscSlhHSEn4jDiDY+UpdEREQSKvU0eH3AafDV0x8n4vDhunOoYWOC/R+0g9zgxRf1JSKiyqNcp8HPmjULy5cvL9S+fPlyzJkzp7S7I6owPQJcYW1qhFupD7H3SpLU5RARkYRKHYCWLl2KunXrFmqvX78+lixZopOiiMqD0kiOvkHuAICVEdHSFkNERJIqdQBKTEwstPgoADg4OCAhIUEnRRGVl4HNPSGTAQev3cP1pAdSl0NERBIpdQByd3fH4cOHC7UfPnwYrq6uOimKqLy425oitG7+daxWH+WUeCIifVXqADR8+HCMHz8eK1asQExMDGJiYrB8+XJMmDAB77zzTnnUSKRTQ0LyF9v969QtPMjJk7gaIiKSQqmnwX/44YdISUnBe++9h9zcXACAUqnElClTMG3aNJ0XSKRrLXzsUdPBDDfvZmL96VsYHOwldUmVhkotcDwqBUkZ2XC0UKKpty1nyxFRtVTmafAPHjzA5cuXYWJigtq1a0OhUOi6NslwGnz1t/JINMI2XYSPgxl2TWwDmYxf8tsuJGDG5ktISPvfVd5drJQI6+6Hzv6Fz/sjIqpsynUafAFzc3O89NJL8PDwwL///ovLly+XdVdEFe61Jm4wM5bjxt1MHLmRLHU5ktt2IQGjVp/WCj8AkJiWjVGrT2PbBU5wIKLqpdQBqE+fPvj+++8B5K8BFhQUhD59+qBhw4ZYt26dzgskKg8WSiO8HlgDAPCLnq8Sr1ILzNh8CUV1BRe0zdh8CSo1r5lKRNVHqQPQgQMH0KpVKwDAhg0bIITA/fv38d133+HLL7/UeYFE5aXg3J/dl+8gLiVL2mIkdDwqpVDPz5MEgIS0bByPSqm4ooiIylmpA1BaWhpsbW0BANu2bcPrr78OU1NTdOvWDdeuXdN5gUTlpZajOVrWsodaAL8di5W6HMkkpRcffrS2yyjZdkREVUGZrgMUERGBzMxMbNu2DR07dgQApKamQqlU6rxAovI0ODh/SvzaE7HIfqSSuJqKJYTAoWv38N2ekv3DxdGCf99EVH2Uehr8+PHjMWDAAJibm8PT0xNt27YFkD801qBBA13XR1SuQus5wc3aBPH3H2LT2dvo83ipjOruRHQKvtl+FcdKMKwlA+BslT8lnoiouih1D9B7772Ho0ePYvny5Th06BAMDPJ3UbNmTZ4DRFWO3ECGQY97gVYeiUYZrwpRZZyNu4/By4/jjSUROBaVAmO5Ad5q4YU5rzeEDPlh52kCQFh3P14PiIiqlVL3AAFAYGAgAgMDtdq6deumk4KIKlrfIHf8387/cPF2Ok7H3kegp43UJenclcR0fLvjP+y8dAcAYGggQ5+X3DGmXS24WpsAAKxMDAtdB6iAnXn1uc4XERFQxgBEVJ3YmBmjRyNX/HnqFlYeia5WAejG3QeYv+satpy7DSEAAxnwauMaGBdaGx52plrbdvZ3wct+zlpXgv7rVBzWnY7HhPBI/DuuFSyURhIdCRGRbjEAEQEYEuKFP0/dwtbzCfikWz04WlbtE37jUrLw3e5rWHf6Fgou3/NKQxeM71AHtRzNi32e3ECGYB87zX1/N0scvZmCW6kP8cWWS5jbu1F5l05EVCHKfCVoourE380KgZ42yFML/H48TupyyiwxLRufbDyP9t/uw5+n8sNPh3pO2Dq2Fb7v3+SZ4acoFkojzOvTCDIZ8MfJW9hxMbGcKiciqlgMQESPFUyJ/+1YDHLz1BJXUzr3HuTgiy2X0PrrvVh9NBaPVAKtattj4+gW+GlIEPxcy76mXbOadni3VU0AwLT153HvQY6uyiYikkyZAtDBgwcxcOBABAcHIz4+HgDw66+/4tChQzotjqgidfF3gYOFAkkZOdheRXo67mflYu62K2g9dy9+PhSF3Dw1mnrZIvzd5vj17WYIcLfWyetM7FgHdZ0tkJyZi6nrzlf72XJEVP2VOgCtW7cOnTp1gomJCc6cOYOcnPx/DWZkZGDmzJk6L5CoohgbGqB/Uw8AwKqIaGmLeY6M7Ef4bvc1tJqzF4v23UBWrgqNalhh1bCmCB/RHM1q2j1/J6WgMJTj//oGwFhugF2X7+CPk1V3mJCICChDAPryyy+xZMkS/PjjjzAy+t+MkJCQEJw+fVqnxRFVtP7NPGBoIMOJ6FRcvJ0mdTmFPMxVYen+G2g9dy/m7fwPGTl5qOtsgR8HB2Hj6BZoXccBMln5XK+nnoslJnWsAwD4fPMlxCbr7/ppRFT1lToAXb16Fa1bty7Ubmlpifv37+uiJiLJOFkq0dnfGQCw6kiMxNX8T06eCiuPRKP113sx698rSM16hJoOZlj4ZmNsHdsKL/s5lVvwedLwVjXR1NsWmbkqTPwjkivEE1GVVeoA5OLiguvXrxdqP3ToEGrWrKmTooikNDTECwCwMTIe97NyJa3lkUqNtcdj0e7rfQjbdBF3M3JQw8YE37zRCDvGt0b3Rq4wqMArNMsNZPj2jUYwVxjiZEwqlh64UWGvTUSkS6UOQCNGjMC4ceNw7NgxyGQy3L59G7/99hsmT56M9957rzxqJKpQgZ428HOxRE6eWrJzXVRqgQ1nbqHDvP2Yuv48bqdlw9lSia9e9ceeSW3RO7AGDOXSTOJ0tzVFWHc/AHh8Be3KN1RIRPQ8pb4Q4ocffoi0tDS0a9cO2dnZaN26NRQKBSZPnowxY8aUR41EFUomk2FIiCemrDuPVRExeLtlzQpbB0utFth2MRHzdv6H60kPAAD25sYY1bYWBjTzgNJIXiF1PE/vwBrYdfkOtl+8gwnhkdg0pmWlqY2IqCRkoozzWbOysnDp0iWo1Wr4+fnB3Lx0F1irzNLT02FlZYW0tDRYWpb9+ilUdWU/UqH5rN24n/UIPw0OQgc/p3J9PSEE9l5Nwrc78tckAwArEyOMaFMTQ4K9YKaofBdtT36Qg07zD+LegxwMb+mNT17xk7okItJzpfn+LnUf+rBhw5CRkQFTU1MEBQWhadOmMDc3R2ZmJoYNG1bmookqE6WRHH2D3AEAK8t5Svzh6/fw2uIjGPbLSVy8nQ5zhSHGhdbGwSnt8F7bWpUy/AD5C6TOeb0BAODnw1E4cuOexBUREZVcqXuA5HI5EhIS4OjoqNV+7949ODs7Iy8vT6cFSoE9QATkr6fV+uu9EALYPakNfBx028t5MjoF3+74DxE3kwEASiMDDAnxwojWPrA1M9bpa5WnaevP4ffjcXC1UmLbhNaw5IKpRCSR0nx/l/iflunp6RBCQAiBjIwMKJX/WyxSpVJh69athUIRUVXmbmuK0LqO2HU5Cb9GxGB6j/o62e/5W2n4dudV7Lt6FwBgLDdA/2YeeK+dDxwtqt4irJ9088Ph68mITcnC9L8vYl7fAKlLIiJ6rhIHIGtra8hkMshkMtSpU6fQ4zKZDDNmzNBpcURSGxLihV2Xk/DXqVuY3MkX5i8wHHU1MQPzdl7F9ot3AACGBjK8EeSO99vXgqu1ia5KrnBmCkP8X99GeGNJBNafiUcHPyd0beAidVlERM9U4k/zvXv3QgiB9u3bY926dbC1tdU8ZmxsDE9PT7i6upZLkURSaeFjj5oOZrh5NxMbTt/CoGCvUu/j5t0HmL/rGjafuw0hAJkMeDXADeM61IannZnui5ZAoKctRrX1wQ97b+CjDecR5GkDR8uq15tFRPqj1OcAxcTEwMPDo8irzsbGxsLDw0NnxUmF5wDRk345HIXpmy+hlqM5dk5oXeIrLselZGHhnmtYdzpec8Xkbg1cML5DbdR2sijPkiWRm6fGq4sO4+LtdLT1dcCKoS9VyNWpiYgKlOsssJo1a+Lu3buF2pOTk+Ht7V3a3RFVeq8H1oCZsRzXkx7gyI3k525/Jz0bn268gPbf7sMfJ29BpRYIreuILe+3xA8DmlTL8APkLyY7v28AjA0NsO/qXfx2LFbqkoiIilXqExqK6zB68OCB1onRRNWFhdIIrwfWwKqIGPxyOAoGMhmSMrLhaKFEU29bzUUSkx/kYMn+G1gVEYOcPDUAoGUte0zsWAdNPGykPIQKU9vJAlM618UXWy7hq38uo0Ute3jbV49hPiKqXkocgCZOnAgg/2Tnzz77DKampprHVCoVjh07hoCAAJ0XSFQZDA72xKqIGOy8nISdl5M07S5WSkzu6Iuoe5lYfjgKWbkqAECQpw0mdfRFsI+dVCVL5q0QL+y+fAdHbiRjQngk/hoZLNmyHURExSlxADpz5gyA/B6g8+fPw9j4f9cpMTY2RqNGjTB58mTdV0hUCRQsS/G0hLRsTPrzrOZ+AzcrTOpYB23qOOjt+S8GBjJ880YjdJp/AJFx97Fo3w2MDa0tdVlERFpKfRL0W2+9hQULFlTrk4N5EjQ9SaUWaDlnDxLSsovdxtBAhoVvNkZnf2e9DT5P23gmHuPDIyE3kGHDeyFoWMNa6pKIqJor15OgV6xYAUtLS1y/fh3bt2/Hw4cPARR/bhBRVXc8KuWZ4QcA8tQC1qbGDD9P6Bngim4NXaBSC0wIj8TDx8ODRESVQakDUEpKCkJDQ1GnTh107doVCQkJAIDhw4dj0qRJOi+QSGpJGc8OP6XdTl/IZDJ81csfjhYK3LibiTnbrkhdEhGRRqkD0Pjx42FkZITY2FitE6H79u2Lbdu26bQ4osqgpMtTVMVlLMqbtakxvn6jEQDglyPROHit8CU0iIikUOoAtGPHDsyZMwc1atTQaq9duzZiYmJ0VhhRZdHU2xYuVkoUN7glQ/5ssKbetsVsod/a1HHAoOaeAIDJf57F/axciSsiIipDAMrMzNTq+Slw7949KBQKnRRFVJnIDWQI6+4HAIVCUMH9sO5+musBUWHTutZFTXsz3EnPwad/X5S6HCKi0geg1q1bY9WqVZr7MpkMarUaX3/9Ndq1a6fT4ogqi87+Llg8sAmcrbSHuZytlFg8sAk6+3Pxz2cxNTbEvL4BkBvIsPnsbfwdGS91SUSk50o9Df7SpUto27YtAgMDsWfPHvTo0QMXL15ESkoKDh8+DB8fn/KqtcJwGjwVR6UWOB6VUuSVoOn5/m/nf1iw+xoslYbYPqE1XKxMpC6JiKqRcp0G7+fnh3PnzqFp06Z4+eWXkZmZiddeew1nzpypFuGH6FnkBjIE+9ihZ4Abgn3sGH5KaUz7WmhUwwrp2Xn48K9zUKt5+Qwikkape4D0AXuAiMrPjbsP0O27g8h+pMb07n4Y2oKLKBORbpTm+7vUi6EeOHDgmY+3bt26tLskIj3i42COj7rWw2d/X8Ssf6+gZW171HK0kLosItIzpe4BMjAoPGr25NVvVaqqf7VX9gARlS8hBIasOIED/91FAzcrrH8vBEZcMJWIXlC5ngOUmpqqdUtKSsK2bdvw0ksvYceOHWUumoj0h0wmw9e9G8LKxAjn49OwcPc1qUsiIj1T6iEwKyurQm0vv/wyFAoFJkyYgFOnTumkMCKq3pwslfjqVX+MWXMG3++9jrZ1HdHEw0bqsohIT+isz9nBwQFXr17V1e6ISA+80tAVvQJcoRbAxPBIZOXmSV0SEemJUgegc+fOad3Onj2Lbdu2YdSoUWjUqFGpC1i0aBG8vb2hVCoRGBiIgwcPFrvtvn37IJPJCt2uXNFeZHHdunXw8/ODQqGAn58fNmzYUOq6iKhizOjpDxcrJaKTs/DVP5elLoeI9ESpA1BAQAAaN26MgIAAzf937doVubm5+Pnnn0u1r/DwcIwfPx4ff/wxzpw5g1atWqFLly6IjY195vOuXr2KhIQEza127dqaxyIiItC3b18MGjQIZ8+exaBBg9CnTx8cO3astIdKRBXAysQI3zxeMPW3Y7HYezVJ4oqISB+UehbY0wueGhgYwMHBAUpl6VfCbtasGZo0aYLFixdr2urVq4devXph1qxZhbbft28f2rVrh9TUVFhbWxe5z759+yI9PR3//vuvpq1z586wsbHB77//XqK6OAuMqOLN2HwRKw5Hw8FCge3jW8PWzFjqkoioiinXWWCenp5aN3d39zKFn9zcXJw6dQodO3bUau/YsSOOHDnyzOc2btwYLi4uCA0Nxd69e7Uei4iIKLTPTp06PXOfOTk5SE9P17oRUcWa0rkuajma425GDj7ecB68RisRlacynQS9f/9+dO/eHbVq1ULt2rXRo0ePZ567U5R79+5BpVLByclJq93JyQmJiYlFPsfFxQXLli3DunXrsH79evj6+iI0NFTr4oyJiYml2icAzJo1C1ZWVpqbu7t7qY6FiF6c0kiO+X0DYGggw78XErHhDBdMJaLyU+oAtHr1anTo0AGmpqYYO3YsxowZAxMTE4SGhmLNmjWlLuDJiygC+RdIe7qtgK+vL9555x00adIEwcHBWLRoEbp164ZvvvmmzPsEgGnTpiEtLU1zi4uLK/VxENGL83ezwvgO+ef0hf19EbdSsySuiIiqq1IHoK+++gpz585FeHg4xo4di3HjxiE8PByzZ8/GF198UeL92NvbQy6XF+qZSUpKKtSD8yzNmzfHtWv/u4ias7NzqfepUChgaWmpdSMiaYxs44MmHtbIyMnD5D/PcsFUIioXpQ5AN2/eRPfu3Qu19+jRA1FRUSXej7GxMQIDA7Fz506t9p07dyIkJKTE+zlz5gxcXFw094ODgwvtc8eOHaXaJxFJx1BugHl9AmBqLMfRmylYfrjknytERCVV6itBu7u7Y/fu3ahVq5ZW++7du0t97szEiRMxaNAgBAUFITg4GMuWLUNsbCxGjhwJIH9oKj4+HqtWrQIAzJ8/H15eXqhfvz5yc3OxevVqrFu3DuvWrdPsc9y4cWjdujXmzJmDnj174u+//8auXbtw6NCh0h4qEUnEy94Mn3Tzw0cbzmPutqtoVdsBvs5cMJWIdKfUAWjSpEkYO3YsIiMjERISAplMhkOHDuGXX37BggULSrWvvn37Ijk5GZ9//jkSEhLg7++PrVu3wtPTEwCQkJCgdU2g3NxcTJ48GfHx8TAxMUH9+vXxzz//oGvXrpptQkJCsHbtWnzyySf49NNP4ePjg/DwcDRr1qy0h0pEEnqzqTt2Xb6DPVeSMD48EhtHh0BhKJe6LCKqJkp9HSAA2LBhA7799ltcvpx/1dZ69erhgw8+QM+ePXVeoBR4HSCiyiEpIxud/u8AUrMeYVRbH0zpXFfqkoioEivN93eZAlB1xwBEVHlsu5CAkatPQyYD/hgRjJe8bKUuiYgqqXK9EGKB3Nxc3Lp1C7GxsVo3IiJd6uzvgt6BNSAEMPGPSDzI4YKpRPTiSh2Arl27hlatWsHExASenp7w9vaGt7c3vLy84O3tXR41EpGeC+vuBzdrE8SlPMQXmy9JXQ4RVQOlPgl66NChMDQ0xJYtW+Di4vLMCwwSEemChdII3/ZphDd/PIrwk3Ho4OeEl/1Kfr0wIqKnlToARUZG4tSpU6hblycjElHFaV7TDu+0qollB25i6rpzaOzRGvbmCqnLIqIqqtRDYH5+frh371551EJE9EyTOtZBXWcLJGfmYuo6LphKRGVXogD05Crpc+bMwYcffoh9+/YhOTmZq6gTUYVRGMrxf30DYCw3wK7Ld/DnyVtSl0REVVSJpsEbGBhonetT1OKiBW0qlUr3VVYwToMnqtyW7L+B2f9egZmxHP+Oaw0PO1OpSyKiSqA0398lOgdo7969OimMiEgX3mlVE3suJ+F4dAom/hGJ8BHBkBtwQgYRlRwvhFgE9gARVX5xKVnosuAgHuTkYUrnuhjV1kfqkohIYjrvATp37lyJX7xhw4Yl3paIqKzcbU3xWXc/fPjXOczbeRWt69ijvquV1GVJTqUWOB6VgqSMbDhaKNHU25a9Y0RFKNU5QM/blOcAEVFFEkJgxK+nsOPSHfg6WeDvMS2gNNLfBVO3XUjAjM2XkJCWrWlzsVIirLsfOvu7SFgZUcXQeQ9QVFSUTgojItIlmUyGWa81wOnYVFy9k4Fvd1zFx938pC5LEtsuJGDU6tN4+p+piWnZGLX6NBYPbMIQRPQEngNUBPYAEVUtuy7dwfBVJyGTAWuGN0ewj53UJVUolVqg5Zw9Wj0/T5IBcLZS4tCU9hwOo2pN5z1AmzZtQpcuXWBkZIRNmzY9c9sePXqUvFIiIh3o4OeEN5u64/fjcZj851n8O74VLJVGUpdVYY5HpRQbfgBAAEhIy8bxqBS9C4dExSlRAOrVqxcSExPh6OiIXr16FbtddTkHiIiqnk+6+eHw9WTEpmRh+qaLmNcnQOqSyo0QArEpWTgZnYqTMSnYeyWpRM9Lyig+JBHpmxIFILVaXeT/ExFVFmYKQ8zr0wh9lkZg/el4vFzPCV0aVI9zXh6p1Lh0Ox0nolNwKiYVJ6JTce9BTqn342ihLIfqiKqmUi+GSkRUWQV52WJkGx8s2ncDH204j0BPGzhaVr0v/fTsRzgdk/o47KTgbFwaHj7S7l03ksvQwM0KQV62aOJujc82XcTdjJxCJ0ED/zsHqKm3bYXUT1QVlDgAHTt2DCkpKejSpYumbdWqVQgLC0NmZiZ69eqFhQsXQqHg6sxEJJ3xHepg39W7uJSQjg/XncOKoS8VWrqnMhFCIP7+Q81w1sno/BltT09PsTIxQqCnDYK8bBDkaYuGNay0p/zLgFGrT0MGFBmCwrr78QRooieUeBZYly5d0LZtW0yZMgUAcP78eTRp0gRDhw5FvXr18PXXX2PEiBGYPn16edZbITgLjKhq++9OBl5ZeAi5eWp89ao/BjTzlLokjTyVGlcSM3AyOgUnY1JxMjoViemFz83xtDPNDzyetnjJywY+DuYweE6AKeo6QMZyA3z3ZgCnwJNe0PksMACIjIzEF198obm/du1aNGvWDD/++CMAwN3dHWFhYdUiABFR1VbHyQIfdvLFl/9cxpdbLiPExx7e9maS1PIgJw+Rsfc15++ciU1FZq72cJahgQz1XS0R5GWLIE8bBHrZlOl8nc7+LnjZzxnHo1Jw9U46Pt98CbkqNVysTHR1OETVRokDUGpqKpycnDT39+/fj86dO2vuv/TSS4iLi9NtdUREZTSshTd2X05CxM1kTAiPxF8jg2EoNyj3101Iyx/OKjh/53JCOtRP9bNbKAzRxNMGQZ42CPKyRYC7NUyMdXMFa7mBDME+dgj2scO5W2lYfzoeSw/cwKIBgTrZP1F1UeIA5OTkhKioKLi7uyM3NxenT5/GjBkzNI9nZGTAyEh/rrtBRJWbgYEM3/RphM7zDyAy7j4W77uB90Nr6/Q1VGqB/+5kPB7Kyj9/J/7+w0LbuVmb4CUvGwQ+7uGp42RRIefjjGjtg/Wn4/HvhURE3cuUrBeMqDIqcQDq3Lkzpk6dijlz5mDjxo0wNTVFq1atNI+fO3cOPj5cjZmIKg83axN83rM+JoSfxYLd19CqtgMePlKVeaHQrNw8RMbdx6noVJyMScXpmFRk5ORpbWMgA/xcLRHkaas5YdnZSpqZaL7OFmhf1xF7riRh2YGbmPVaA0nqIKqMShyAvvzyS7z22mto06YNzM3NsXLlShgbG2seX758OTp27FguRRIRlVWvADfsupSEf84n4PUlR6B6YjzqeQuFJmVka8LOyegUXLydjrynxrPMjOVo4mmjOWE5wMMa5orKc4WRkW18sOdKEtadvoUJL9fmtYCIHiv1WmBpaWkwNzeHXK49Xp2SkgJzc3OtUFRVcRYYUfXy18k4TP7rXKH2gr6fxQOboKOfM27cfYATj6ejn4pJRUxyVqHnOFsqH/fs5J+/U9fZokLOLSorIQReW3wEZ2Lv4722Pviwc12pSyIqN6X5/uZiqEVgACKqPp63UCgAKAwNoDA0QHq29nCWTAb4OlngJa/84axATxu4WZtU6usKFWX7xUSM+PUULJSGiJgWWql6qIh0qVymwRMRVUXPWygUAHLy1MjJU8PESI4Ad+v8Hh4vWzT2sK4Wi6q+XM8JNR3McPNuJn4/Fot3WteUuiQiyTEAEVG1VtIFQCe9XAcj2/rAqBIPZ5WVgYEMI1rXxJR15/HzoSgMCfGCsWH1O06i0uBfABFVayU96TfIy7Zahp8CvRq7wdFCgcT0bPwdGS91OUSSq75/7UREAJp628LFSoniztqRIX82WHVfKFRhKMewlt4AgKUHbkL99NUZifQMAxARVWtyAxnCuvsBQKEQVHBfXxYK7d/MAxYKQ1xPeoDdV5KkLodIUgxARFTtdfZ3weKBTQpdkNDZSonFA5vozUKhlkojDGievzDs0v03JK6GSFo8CZqI9MKTC4WW9UrQ1cGwFl5YfihKc3HHIK/qPfRHVBz2ABGR3ihYKLRngBuCfez0LvwAgKOlEq81cQMALNl/U+JqiKTDAEREpGfeaV0TMhmw6/IdXLuTIXU5RJJgACIi0jM+Dubo6OcEIH9GGJE+YgAiItJDI9v4AAD+joxHQtpDiashqngMQEREeqixhw2aetvikUpg+aEoqcshqnAMQEREemrU416gNcdikZb1SOJqiCoWAxARkZ5q6+sAXycLZOaqsPpYjNTlEFUoBiAiIj0lk8kwok3+yvArDkcj+5FK4oqIKg4DEBGRHuveyBWuVkrce5CD9ae5SCrpDwYgIiI9ZiQ3wNut8nuBlh24ARUXSSU9wQBERKTn+r3kDisTI0QnZ2H7xUSpyyGqEAxARER6zkxhiCHB/1skVQj2AlH1xwBEREQYHOIFhaEBzt5KQ8TNZKnLISp3DEBERAR7cwX6BLkD4CKppB8YgIiICADwTquaMJABB/67i0u306Uuh6hcMQAREREAwMPOFF0buAAAlh64IXE1ROWLAYiIiDQKFkndci4BcSlZEldDVH4YgIiISMPfzQota9lDpRb4mYukUjXGAERERFoKeoHWnohFSmauxNUQlQ8GICIi0tKilh383SyR/UiNVRHRUpdDVC4YgIiISItMJsOI1vm9QCuPRCMrN0/iioh0jwGIiIgK6eLvDA9bU6RmPcIfJ+KkLodI5xiAiIioEEO5Ad5p5Q0A+PFgFPJUaokrItItBiAiIirSG0HusDMzRvz9h/jnfILU5RDpFAMQEREVSWkkx9AQLwD5y2NwkVSqTiQPQIsWLYK3tzeUSiUCAwNx8ODBEj3v8OHDMDQ0REBAQKHH5s+fD19fX5iYmMDd3R0TJkxAdna2jisnIqr+BgV7wtRYjssJ6Thw7Z7U5RDpjKQBKDw8HOPHj8fHH3+MM2fOoFWrVujSpQtiY2Of+by0tDQMHjwYoaGhhR777bffMHXqVISFheHy5cv4+eefER4ejmnTppXXYRARVVvWpsbo95IHAGDJPi6PQdWHpAFo3rx5ePvttzF8+HDUq1cP8+fPh7u7OxYvXvzM540YMQL9+/dHcHBwocciIiLQokUL9O/fH15eXujYsSPefPNNnDx5srwOg4ioWnu7lTcMDWSIuJmMs3H3pS6HSCckC0C5ubk4deoUOnbsqNXesWNHHDlypNjnrVixAjdu3EBYWFiRj7ds2RKnTp3C8ePHAQA3b97E1q1b0a1bt2L3mZOTg/T0dK0bERHlc7M2QY9GrgC4SCpVH4ZSvfC9e/egUqng5OSk1e7k5ITExMQin3Pt2jVMnToVBw8ehKFh0aX369cPd+/eRcuWLSGEQF5eHkaNGoWpU6cWW8usWbMwY8aMsh8MEVE1926bmlh/Jh7/XkhE9L1MeNmbSV0S0QuR/CRomUymdV8IUagNAFQqFfr3748ZM2agTp06xe5v3759+Oqrr7Bo0SKcPn0a69evx5YtW/DFF18U+5xp06YhLS1Nc4uL40W/iIieVNfZEu18HSAEsOzgTanLIXphkvUA2dvbQy6XF+rtSUpKKtQrBAAZGRk4efIkzpw5gzFjxgAA1Go1hBAwNDTEjh070L59e3z66acYNGgQhg8fDgBo0KABMjMz8e677+Ljjz+GgUHhzKdQKKBQKMrhKImIqo+RbXyw9+pd/HXqFsZ3qA1HC6XUJRGVmWQ9QMbGxggMDMTOnTu12nfu3ImQkJBC21taWuL8+fOIjIzU3EaOHAlfX19ERkaiWbNmAICsrKxCIUcul0MIwWtYEBG9gKbetmjsYY3cPDVWHomWuhyiFyJZDxAATJw4EYMGDUJQUBCCg4OxbNkyxMbGYuTIkQDyh6bi4+OxatUqGBgYwN/fX+v5jo6OUCqVWu3du3fHvHnz0LhxYzRr1gzXr1/Hp59+ih49ekAul1fo8RERVScFi6SOXH0Kv0bEYFTbWjBXSPo1QlRmkv7m9u3bF8nJyfj888+RkJAAf39/bN26FZ6engCAhISE514T6GmffPIJZDIZPvnkE8THx8PBwQHdu3fHV199VR6HQESkVzr6OaGmgxlu3s3E78di8U7rmlKXRFQmMsFxoULS09NhZWWFtLQ0WFpaSl0OEVGlEn4iFlPWnYezpRIHPmwHY0PJ59MQASjd9zd/a4mIqFR6NXaDo4UCienZ+DsyXupyiMqEAYiIiEpFYSjHsJbeAIBlB25CreZAAlU9DEBERFRq/Zt5wEJhiGtJD7DnSpLU5RCVGgMQERGVmqXSCP2bP14kdT+Xx6CqhwGIiIjKZFgLbxjLDXAyJhUno1OkLoeoVBiAiIioTJwslXi1sRsAYMl+Lo9BVQsDEBERldm7bWpCJgN2Xb6Da3cypC6HqMQYgIiIqMx8HMzR0S9//cZlB9gLRFUHAxAREb2QEW18AAAbI+ORkPZQ4mqISoYBiIiIXkgTDxs09bbFI5XAisPRUpdDVCIMQERE9MJGtslfE2zNsVikPXwkcTVEz8cAREREL6ydryN8nSzwICcPq4/GSF0O0XMxABER0QuTyWQY8bgXaMXhaGQ/UklcEdGzMQAREZFOdG/kClcrJe49yMH601wklSo3BiAiItIJI7kB3m6V3wu07MANqLhIKlViDEBERKQz/V5yh5WJEaKTs7DjYqLU5RAViwGIiIh0xkxhiMHBngDyF0kVgr1AVDkxABERkU4NCfGCwtAAZ2+l4ehNLpJKlRMDEBER6ZS9uQJvBNUAkN8LRFQZMQAREZHOvdvKBwYyYP9/d3HpdrrU5RAVwgBEREQ652Fniq4NXADkzwgjqmwYgIiIqFyMfLxI6uZzCYhLyZK4GiJtDEBERFQu/N2s0LKWPVRqgZ8PRUldDpEWBiAiIio3BctjhJ+IQ2pmrsTVEP0PAxAREZWblrXsUd/VEg8fqbAyIlrqcog0GICIiKjcyGQyzblAK49E42EuF0mlyoEBiIiIylUXf2e425ogNesR/jgZJ3U5RAAYgIiIqJwZyg3w7uNFUn88eBN5KrXEFRExABERUQV4I8gddmbGuJX6EP+cT5C6HCIGICIiKn9KIzmGhHgBAJbsv8lFUklyDEBERFQhBgd7wsRIjssJ6Th47Z7U5ZCeYwAiIqIKYW1qjH5N3QFwkVSSHgMQERFVmOGtasLQQIYjN5Jx7tZ9qcshPcYAREREFcbN2gQ9GrkCAJbuvylxNaTPGICIiKhCvft4eYx/LyQg+l6mxNWQvmIAIiKiClXX2RLtfB2gFsCyg+wFImkwABERUYUrWB7jr1O3cDcjR+JqSB8xABERUYVr6m2LAHdr5Oap8cuRKKnLIT3EAERERBXuyUVSf42IwYOcPIkrIn3DAERERJJ42c8JNe3NkJ6dh7XHY6Uuh/QMAxAREUlCbiDDu63zZ4T9dDAKuXlcJJUqDgMQERFJ5tUmbnCwUCAxPRubzt6WuhzSIwxAREQkGYWhHMNaeAMAlu6/AbWai6RSxWAAIiIiSQ1o7gELhSGuJT3AnitJUpdDeoIBiIiIJGWpNEL/5h4AgKUHuEgqVQwGICIiktywFt4wlhvgRHQqTsWkSF0O6QEGICIikpyTpRKvNnYDACzhIqlUARiAiIioUnindU3IZMDOS3dwPSlD6nKommMAIiKiSqGWozlerucEAFjKXqBqS6UWiLiRjL8j4xFxIxkqiWb+GUryqkREREUY2dYHOy7dwcbIeEzq6AtnK6XUJZEObbuQgBmbLyEhLVvT5mKlRFh3P3T2d6nQWtgDRERElUYTDxs09bLFI5XA8sNcJLU62XYhAaNWn9YKPwCQmJaNUatPY9uFhAqthwGIiIgqlZFt85fHWHMsFmkPH0lcDemCSi0wY/MlFDXYVdA2Y/OlCh0OYwAiIqJKpZ2vI3ydLPAgJw+/HYuRuhwqozyVGrHJWdj/3118+c+lQj0/TxIAEtKycTyq4i6BwHOAiIioUpHJ8hdJnfTnWSw/FI1hLbyhNJJLXRYVQaUWuH3/IaLuZSI6ORPR97Ie/zcTcalZeKQqXY9OUkbxIUnXGICIiKjS6RHgim93XMXttGxsOBOPN5t6SF2S3ioIOQXBJupeFmKSMxGVnIm4lGeHHGNDA3jamsLSxAinYlKf+1qOFhV30jsDEBERVTpGcgMMa+mNL/+5jGUHbqJPkDvkBjKpy6q2CkJOTHIWoh4HnZjkTETdy0RcykPkqtTFPrcg5HjamcHb3hRe9mbwsjODl70ZXCyVMDCQQaUWaDlnDxLTsos8D0gGwNlKiabetuV2jE9jACIiokrpzaYeWLjnOqLuZWLHxUR0aVCx06SloFILHI9KQVJGNhwt8gOBroKfWi1wO+2h1jBVdHImopOzEJuc9eyQIzeAh51pfrCxyw853vZm8LQzhYuVyXNrlBvIENbdD6NWn4YM0ApBBc8M6+5XoSGXAYiIiColM4UhBgd7YuGe61iy/wY6+ztDJqu+vUC6uEaOWi2QkJ79eKiqoBcnP/DEpmQhN+/ZIcfd1gTej3twPO3N4G1nBi/7koWc5+ns74LFA5sUOkZnia4DJBNCSHMJxkosPT0dVlZWSEtLg6WlpdTlEBHprXsPctBi9h7k5Knx+zvNEexjJ3VJ5aLgGjlPfyEXRI7FA5toAkJByIm5l6kZropOzsoftnpOyDGSy+Bha6oZosofrsq/72r94iGnJMqzl6s039+S9wAtWrQIX3/9NRISElC/fn3Mnz8frVq1eu7zDh8+jDZt2sDf3x+RkZFaj92/fx8ff/wx1q9fj9TUVHh7e+Pbb79F165dy+koiIioPNibK/BGUA2sPhqLpQduVMsAVJJr5Ez68yz+OnULsSlZiEnOQs5zQo67rSm87cwKnZdTUSHnWeQGskrxc5Q0AIWHh2P8+PFYtGgRWrRogaVLl6JLly64dOkSPDyKP+M/LS0NgwcPRmhoKO7cuaP1WG5uLl5++WU4Ojrir7/+Qo0aNRAXFwcLC4vyPhwiIioH77SqiTXHYrHv6l1cTkhHPZeq3TOf/UiFpPQcJKZn4056No5FJT/zGjkAkJmjwq7LSZr7hgaPe3I0Jxzn9+J425vBxUoJQzkv8/c8kg6BNWvWDE2aNMHixYs1bfXq1UOvXr0wa9asYp/Xr18/1K5dG3K5HBs3btTqAVqyZAm+/vprXLlyBUZGRmWqi0NgRESVy+g1p/HPuQT0CnDF/H6NpS6nSCq1wL0HObiTno3EtGzcycjBnbT8kJOYno2k9BzcycjG/ayyXd26d2ANdG/kCm87M7haM+QUpUoMgeXm5uLUqVOYOnWqVnvHjh1x5MiRYp+3YsUK3LhxA6tXr8aXX35Z6PFNmzYhODgYo0ePxt9//w0HBwf0798fU6ZMgVxe9IW0cnJykJOTo7mfnp5exqMiIqLyMLK1D/45l4BNZ2+jfT1HCAGdnz9SHCEE0h4+wp0nem2SHoeaO+n5gedOejbuZuSgpCs5KAwN4GylhJOlEnIDGSJuJD/3Oa83qVEpho6qC8kC0L1796BSqeDk5KTV7uTkhMTExCKfc+3aNUydOhUHDx6EoWHRpd+8eRN79uzBgAEDsHXrVly7dg2jR49GXl4ePvvssyKfM2vWLMyYMePFDoiIiMpNgxpWqOtsjiuJDzD290hN+4uuJP4wV6XpobnzuJem4P/vPBFwnnXOzZPkBjI4mCvgZKWEk4UCTpZKOFsp4Wih0AQeJ0slLJWGmhltlfEaOfpA8pOgn57SKIQocpqjSqVC//79MWPGDNSpU6fY/anVajg6OmLZsmWQy+UIDAzE7du38fXXXxcbgKZNm4aJEydq7qenp8Pd3b2MR0RERLq27UICriQ+KNResJL4k7OkgPx1qO4+yMnvtUnLRlLG42Gp9Jwn/j8b6dl5Ja7BxtRIE2CcLBVwtlTC8fF958dtduaKUvdIVcZr5OgDyQKQvb095HJ5od6epKSkQr1CAJCRkYGTJ0/izJkzGDNmDID8sCOEgKGhIXbs2IH27dvDxcUFRkZGWsNd9erVQ2JiInJzc2FsbFxo3wqFAgqFQsdHSEREulAwS6ooBWFh4h9n8efJuPzzbtJzcO9BDkp6hquJkbzIXpqCkONkqYSDhaJc1yOrbNfI0QeSBSBjY2MEBgZi586dePXVVzXtO3fuRM+ePQttb2lpifPnz2u1LVq0CHv27MFff/0Fb29vAECLFi2wZs0aqNVqGBjknyD233//wcXFpcjwQ0REldvxqJTnzpLKylVh95W7Wm2GBjI4Wijg+EQPTf7Q1ONeG6v8xywUhpXiAoud/V3wsp9zuV0jh7RJOgQ2ceJEDBo0CEFBQQgODsayZcsQGxuLkSNHAsgfmoqPj8eqVatgYGAAf39/rec7OjpCqVRqtY8aNQoLFy7EuHHj8P777+PatWuYOXMmxo4dW6HHRkREulHSFcL7BrmjY30nTQ+OnZkxDKpYeKgs18jRB5IGoL59+yI5ORmff/45EhIS4O/vj61bt8LT0xMAkJCQgNjY2FLt093dHTt27MCECRPQsGFDuLm5Ydy4cZgyZUp5HAIREZWzkq4Q3quxG8MDlRiXwigCrwNERFR5lHSW1KEp7TlcpOdK8/3NqygREVGlVjBLCvjfrKgCnCVFZcUARERElV7BLClnK+3hMGcrZaEp8EQlIfl1gIiIiEqCs6RIlxiAiIioyuAsKdIVDoERERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3uGVoIsgRP56w+np6RJXQkRERCVV8L1d8D3+LAxARcjIyAAAuLu7S1wJERERlVZGRgasrKyeuY1MlCQm6Rm1Wo3bt2/DwsICMpluF9lLT0+Hu7s74uLiYGlpqdN9VwbV/fiA6n+MPL6qr7ofI4+v6iuvYxRCICMjA66urjAwePZZPuwBKoKBgQFq1KhRrq9haWlZbX+xgep/fED1P0YeX9VX3Y+Rx1f1lccxPq/npwBPgiYiIiK9wwBEREREeocBqIIpFAqEhYVBoVBIXUq5qO7HB1T/Y+TxVX3V/Rh5fFVfZThGngRNREREeoc9QERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBUAWbNmoWXXnoJFhYWcHR0RK9evXD16lWpy9KpxYsXo2HDhpqLWgUHB+Pff/+VuqxyM2vWLMhkMowfP17qUnRm+vTpkMlkWjdnZ2epy9Kp+Ph4DBw4EHZ2djA1NUVAQABOnToldVk64eXlVejnJ5PJMHr0aKlL05m8vDx88skn8Pb2homJCWrWrInPP/8carVa6tJ0JiMjA+PHj4enpydMTEwQEhKCEydOSF1WmRw4cADdu3eHq6srZDIZNm7cqPW4EALTp0+Hq6srTExM0LZtW1y8eLHC6mMAqgD79+/H6NGjcfToUezcuRN5eXno2LEjMjMzpS5NZ2rUqIHZs2fj5MmTOHnyJNq3b4+ePXtW6C9zRTlx4gSWLVuGhg0bSl2KztWvXx8JCQma2/nz56UuSWdSU1PRokULGBkZ4d9//8WlS5fw7bffwtraWurSdOLEiRNaP7udO3cCAN544w2JK9OdOXPmYMmSJfj+++9x+fJlzJ07F19//TUWLlwodWk6M3z4cOzcuRO//vorzp8/j44dO6JDhw6Ij4+XurRSy8zMRKNGjfD9998X+fjcuXMxb948fP/99zhx4gScnZ3x8ssva9bjLHeCKlxSUpIAIPbv3y91KeXKxsZG/PTTT1KXoVMZGRmidu3aYufOnaJNmzZi3LhxUpekM2FhYaJRo0ZSl1FupkyZIlq2bCl1GRVm3LhxwsfHR6jVaqlL0Zlu3bqJYcOGabW99tprYuDAgRJVpFtZWVlCLpeLLVu2aLU3atRIfPzxxxJVpRsAxIYNGzT31Wq1cHZ2FrNnz9a0ZWdnCysrK7FkyZIKqYk9QBJIS0sDANja2kpcSflQqVRYu3YtMjMzERwcLHU5OjV69Gh069YNHTp0kLqUcnHt2jW4urrC29sb/fr1w82bN6UuSWc2bdqEoKAgvPHGG3B0dETjxo3x448/Sl1WucjNzcXq1asxbNgwnS/oLKWWLVti9+7d+O+//wAAZ8+exaFDh9C1a1eJK9ONvLw8qFQqKJVKrXYTExMcOnRIoqrKR1RUFBITE9GxY0dNm0KhQJs2bXDkyJEKqYGLoVYwIQQmTpyIli1bwt/fX+pydOr8+fMIDg5GdnY2zM3NsWHDBvj5+Uldls6sXbsWp0+frrLj8c/TrFkzrFq1CnXq1MGdO3fw5ZdfIiQkBBcvXoSdnZ3U5b2wmzdvYvHixZg4cSI++ugjHD9+HGPHjoVCocDgwYOlLk+nNm7ciPv372Po0KFSl6JTU6ZMQVpaGurWrQu5XA6VSoWvvvoKb775ptSl6YSFhQWCg4PxxRdfoF69enBycsLvv/+OY8eOoXbt2lKXp1OJiYkAACcnJ612JycnxMTEVEgNDEAVbMyYMTh37ly1S/MA4Ovri8jISNy/fx/r1q3DkCFDsH///moRguLi4jBu3Djs2LGj0L/OqosuXbpo/r9BgwYIDg6Gj48PVq5ciYkTJ0pYmW6o1WoEBQVh5syZAIDGjRvj4sWLWLx4cbULQD///DO6dOkCV1dXqUvRqfDwcKxevRpr1qxB/fr1ERkZifHjx8PV1RVDhgyRujyd+PXXXzFs2DC4ublBLpejSZMm6N+/P06fPi11aeXi6R5KIUSF9VoyAFWg999/H5s2bcKBAwdQo0YNqcvROWNjY9SqVQsAEBQUhBMnTmDBggVYunSpxJW9uFOnTiEpKQmBgYGaNpVKhQMHDuD7779HTk4O5HK5hBXqnpmZGRo0aIBr165JXYpOuLi4FArj9erVw7p16ySqqHzExMRg165dWL9+vdSl6NwHH3yAqVOnol+/fgDyg3pMTAxmzZpVbQKQj48P9u/fj8zMTKSnp8PFxQV9+/aFt7e31KXpVMEM08TERLi4uGjak5KSCvUKlReeA1QBhBAYM2YM1q9fjz179lS7X+TiCCGQk5MjdRk6ERoaivPnzyMyMlJzCwoKwoABAxAZGVntwg8A5OTk4PLly1ofTlVZixYtCl1+4r///oOnp6dEFZWPFStWwNHREd26dZO6FJ3LysqCgYH215ZcLq9W0+ALmJmZwcXFBampqdi+fTt69uwpdUk65e3tDWdnZ81sRSD/3LX9+/cjJCSkQmpgD1AFGD16NNasWYO///4bFhYWmrFPKysrmJiYSFydbnz00Ufo0qUL3N3dkZGRgbVr12Lfvn3Ytm2b1KXphIWFRaFztszMzGBnZ1dtzuWaPHkyunfvDg8PDyQlJeHLL79Eenp6tfmX9YQJExASEoKZM2eiT58+OH78OJYtW4Zly5ZJXZrOqNVqrFixAkOGDIGhYfX7eO/evTu++uoreHh4oH79+jhz5gzmzZuHYcOGSV2azmzfvh1CCPj6+uL69ev44IMP4Ovri7feekvq0krtwYMHuH79uuZ+VFQUIiMjYWtrCw8PD4wfPx4zZ85E7dq1Ubt2bcycOROmpqbo379/xRRYIXPN9ByAIm8rVqyQujSdGTZsmPD09BTGxsbCwcFBhIaGih07dkhdVrmqbtPg+/btK1xcXISRkZFwdXUVr732mrh48aLUZenU5s2bhb+/v1AoFKJu3bpi2bJlUpekU9u3bxcAxNWrV6UupVykp6eLcePGCQ8PD6FUKkXNmjXFxx9/LHJycqQuTWfCw8NFzZo1hbGxsXB2dhajR48W9+/fl7qsMtm7d2+R331DhgwRQuRPhQ8LCxPOzs5CoVCI1q1bi/Pnz1dYfTIhhKiYqEVERERUOfAcICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQEVWo6OhoyGQyREZGSl2KxpUrV9C8eXMolUoEBASU+vmV8ZiI6NkYgIj0zNChQyGTyTB79myt9o0bN1bYKsyVTVhYGMzMzHD16lXs3r1b6nLwyy+/wNraWuoyiKo1BiAiPaRUKjFnzhykpqZKXYrO5Obmlvm5N27cQMuWLeHp6Qk7OzsdViUtlUpVLRcKJdIFBiAiPdShQwc4Oztj1qxZxW4zffr0QsNB8+fPh5eXl+b+0KFD0atXL8ycORNOTk6wtrbGjBkzkJeXhw8++AC2traoUaMGli9fXmj/V65cQUhICJRKJerXr499+/ZpPX7p0iV07doV5ubmcHJywqBBg3Dv3j3N423btsWYMWMwceJE2Nvb4+WXXy7yONRqNT7//HPUqFEDCoUCAQEBWov0ymQynDp1Cp9//jlkMhmmT59e7H7mzJmDWrVqQaFQwMPDA1999VWR2xbVg/N0D9vZs2fRrl07WFhYwNLSEoGBgTh58iT27duHt956C2lpaZDJZFo15ebm4sMPP4SbmxvMzMzQrFkzrfet4HW3bNkCPz8/KBQKxMTEYN++fWjatCnMzMxgbW2NFi1aICYmpsjaifQFAxCRHpLL5Zg5cyYWLlyIW7duvdC+9uzZg9u3b+PAgQOYN28epk+fjldeeQU2NjY4duwYRo4ciZEjRyIuLk7reR988AEmTZqEM2fOICQkBD169EBycjIAICEhAW3atEFAQABOnjyJbdu24c6dO+jTp4/WPlauXAlDQ0McPnwYS5cuLbK+BQsW4Ntvv8U333yDc+fOoVOnTujRoweuXbumea369etj0qRJSEhIwOTJk4vcz7Rp0zBnzhx8+umnuHTpEtasWQMnJ6cyv28DBgxAjRo1cOLECZw6dQpTp06FkZERQkJCMH/+fFhaWiIhIUGrprfeeguHDx/G2rVrce7cObzxxhvo3Lmz5lgAICsrC7NmzcJPP/2EixcvwtbWFr169UKbNm1w7tw5RERE4N1339Xb4U4ijQpbdpWIKoUhQ4aInj17CiGEaN68uRg2bJgQQogNGzaIJz8SwsLCRKNGjbSe+3//93/C09NTa1+enp5CpVJp2nx9fUWrVq009/Py8oSZmZn4/fffhRBCREVFCQBi9uzZmm0ePXokatSoIebMmSOEEOLTTz8VHTt21HrtuLg4rZXO27RpIwICAp57vK6uruKrr77SanvppZfEe++9p7nfqFEjERYWVuw+0tPThUKhED/++GORjxcc05kzZ4QQQqxYsUJYWVlpbfP0+2thYSF++eWXIvdX1POvX78uZDKZiI+P12oPDQ0V06ZN0zwPgIiMjNQ8npycLACIffv2FXt8RPqIPUBEemzOnDlYuXIlLl26VOZ91K9fHwYG//socXJyQoMGDTT35XI57OzskJSUpPW84OBgzf8bGhoiKCgIly9fBgCcOnUKe/fuhbm5ueZWt25dAPnn6xQICgp6Zm3p6em4ffs2WrRoodXeokULzWuVxOXLl5GTk4PQ0NASP+d5Jk6ciOHDh6NDhw6YPXu21nEV5fTp0xBCoE6dOlrvy/79+7Wea2xsjIYNG2ru29raYujQoejUqRO6d++OBQsWICEhQWfHQVRVMQAR6bHWrVujU6dO+Oijjwo9ZmBgACGEVtujR48KbWdkZKR1XyaTFdlWkpNxC4Zl1Go1unfvjsjISK3btWvX0Lp1a832ZmZmz93nk/stIIQo1RCQiYlJibcFSvbeTZ8+HRcvXkS3bt2wZ88e+Pn5YcOGDcXuU61WQy6X49SpU1rvyeXLl7FgwQKtWp8+thUrViAiIgIhISEIDw9HnTp1cPTo0VIdE1F1wwBEpOdmz56NzZs348iRI1rtDg4OSExM1Poi1+V1bp78As7Ly8OpU6c0vTxNmjTBxYsX4eXlhVq1amndShp6AMDS0hKurq44dOiQVvuRI0dQr169Eu+ndu3aMDExKfEUeQcHB2RkZCAzM1PTVtR7V6dOHUyYMAE7duzAa6+9hhUrVgDI78VRqVRa2zZu3BgqlQpJSUmF3hNnZ+fn1tS4cWNMmzYNR44cgb+/P9asWVOiYyGqrhiAiPRcgwYNMGDAACxcuFCrvW3btrh79y7mzp2LGzdu4IcffsC///6rs9f94YcfsGHDBly5cgWjR49Gamoqhg0bBgAYPXo0UlJS8Oabb+L48eO4efMmduzYgWHDhhUKBs/zwQcfYM6cOQgPD8fVq1cxdepUREZGYty4cSXeh1KpxJQpU/Dhhx9i1apVuHHjBo4ePYqff/65yO2bNWsGU1NTfPTRR7h+/TrWrFmDX375RfP4w4cPMWbMGOzbtw8xMTE4fPgwTpw4oQllXl5eePDgAXbv3o179+4hKysLderUwYABAzB48GCsX78eUVFROHHiBObMmYOtW7cWW3tUVBSmTZuGiIgIxMTEYMeOHfjvv/9KFQCJqiMGICLCF198UWjIpl69eli0aBF++OEHNGrUCMePHy92hlRZzJ49G3PmzEGjRo1w8OBB/P3337C3twcAuLq64vDhw1CpVOjUqRP8/f0xbtw4WFlZaZ1vVBJjx47FpEmTMGnSJDRo0ADbtm3Dpk2bULt27VLt59NPP8WkSZPw2WefoV69eujbt2+h85oK2NraYvXq1di6dSsaNGiA33//XWt6vVwuR3JyMgYPHow6deqgT58+6NKlC2bMmAEACAkJwciRI9G3b184ODhg7ty5APKHsgYPHoxJkybB19cXPXr0wLFjx+Du7l5s3aamprhy5Qpef/111KlTB++++y7GjBmDESNGlOr4iaobmXj6U4+IiIiommMPEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjv/D8XKDE8OstnMAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "silhouette_scores = []\n",
    "X = normalize(vectorize(data))\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create KMeans instance\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plotting the silhouette scores\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Silhouette scores for different numbers of clusters')\n",
    "plt.xticks(range_n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.82674294e-01, 1.88737914e-15, 6.86199499e-01, 9.05352163e-01],\n",
       "       [7.23266129e-01, 1.00000000e+00, 3.95987903e-01, 5.61580645e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init='auto')\n",
    "kmeans.fit(X)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Epoch 0 loss 41911.05633\n",
      "Iteration 2 Epoch 0 loss 24285.03850781438\n",
      "Iteration 3 Epoch 0 loss 17489.421015228098\n",
      "Iteration 4 Epoch 0 loss 10226.232854024947\n",
      "Iteration 5 Epoch 0 loss 8746.04781797717\n",
      "Iteration 6 Epoch 0 loss 5534.749404080374\n",
      "Iteration 7 Epoch 0 loss 4577.044964954438\n",
      "Iteration 8 Epoch 0 loss 3541.6984062948172\n",
      "Iteration 9 Epoch 0 loss 2393.700003296671\n",
      "Iteration 10 Epoch 0 loss 2122.8460904499075\n",
      "Iteration 11 Epoch 0 loss 2213.7266410289144\n",
      "Iteration 12 Epoch 0 loss 2099.419187209267\n",
      "Iteration 13 Epoch 0 loss 1830.4544687795562\n",
      "Iteration 14 Epoch 0 loss 1508.7822367387034\n",
      "Iteration 15 Epoch 0 loss 1507.1133578680542\n",
      "Iteration 16 Epoch 0 loss 1598.9552081968784\n",
      "Iteration 17 Epoch 0 loss 1583.682577957072\n",
      "Iteration 18 Epoch 0 loss 1152.186331185697\n",
      "Iteration 19 Epoch 0 loss 1258.4320184713326\n",
      "Iteration 20 Epoch 0 loss 1445.793384474852\n",
      "Iteration 21 Epoch 0 loss 1305.505338683935\n",
      "Iteration 22 Epoch 0 loss 1386.8974678711738\n",
      "Iteration 23 Epoch 0 loss 1157.5676832869226\n",
      "Iteration 24 Epoch 0 loss 878.1764107556113\n",
      "Iteration 25 Epoch 0 loss 1028.6280936413825\n",
      "Iteration 26 Epoch 0 loss 1065.2258737709794\n",
      "Iteration 27 Epoch 0 loss 1008.0950269909979\n",
      "Iteration 28 Epoch 0 loss 898.8545067751156\n",
      "Iteration 29 Epoch 0 loss 758.9435003363396\n",
      "Iteration 30 Epoch 0 loss 916.5870730877386\n",
      "Iteration 31 Epoch 0 loss 812.0406962496933\n",
      "Iteration 32 Epoch 0 loss 804.8195341987428\n",
      "Iteration 33 Epoch 0 loss 1059.05311580836\n",
      "Iteration 34 Epoch 0 loss 740.3638123743891\n",
      "Iteration 35 Epoch 0 loss 812.2839120240557\n",
      "Iteration 36 Epoch 0 loss 782.9561330517087\n",
      "Iteration 37 Epoch 0 loss 868.8408103597769\n",
      "Iteration 38 Epoch 0 loss 612.5368806207101\n",
      "Iteration 39 Epoch 0 loss 990.9649168889036\n",
      "Iteration 40 Epoch 0 loss 736.3851771595442\n",
      "Iteration 41 Epoch 0 loss 804.0067587158997\n",
      "Iteration 42 Epoch 0 loss 834.8164344377458\n",
      "Iteration 43 Epoch 0 loss 760.5677834075467\n",
      "Iteration 44 Epoch 0 loss 907.1246281517116\n",
      "Iteration 45 Epoch 0 loss 720.8720851119289\n",
      "Iteration 46 Epoch 0 loss 886.068779005399\n",
      "Iteration 47 Epoch 0 loss 769.8335425828919\n",
      "Iteration 48 Epoch 0 loss 859.7501395803891\n",
      "Iteration 49 Epoch 0 loss 783.0179666951321\n",
      "Iteration 50 Epoch 0 loss 765.9213486170713\n",
      "Iteration 51 Epoch 0 loss 714.8637707028938\n",
      "Iteration 52 Epoch 0 loss 856.8413218729978\n",
      "Iteration 53 Epoch 0 loss 775.4446364096065\n",
      "Iteration 54 Epoch 0 loss 824.342782857823\n",
      "Iteration 55 Epoch 0 loss 706.3907711739299\n",
      "Iteration 56 Epoch 0 loss 633.0441140032661\n",
      "Iteration 57 Epoch 0 loss 715.5154237561911\n",
      "Iteration 58 Epoch 1 loss 956.604990383747\n",
      "Iteration 59 Epoch 1 loss 731.3508310591816\n",
      "Iteration 60 Epoch 1 loss 777.5546997008144\n",
      "Iteration 61 Epoch 1 loss 579.2389082978953\n",
      "Iteration 62 Epoch 1 loss 599.5564121659775\n",
      "Iteration 63 Epoch 1 loss 802.2884071642104\n",
      "Iteration 64 Epoch 1 loss 589.4076548763907\n",
      "Iteration 65 Epoch 1 loss 636.1627014165092\n",
      "Iteration 66 Epoch 1 loss 744.8844031322669\n",
      "Iteration 67 Epoch 1 loss 766.4133113805293\n",
      "Iteration 68 Epoch 1 loss 696.6810455448211\n",
      "Iteration 69 Epoch 1 loss 763.9633492474526\n",
      "Iteration 70 Epoch 1 loss 688.7594649547736\n",
      "Iteration 71 Epoch 1 loss 642.1301878944151\n",
      "Iteration 72 Epoch 1 loss 763.52834005357\n",
      "Iteration 73 Epoch 1 loss 738.9231755887704\n",
      "Iteration 74 Epoch 1 loss 906.5283358088433\n",
      "Iteration 75 Epoch 1 loss 794.9512798861322\n",
      "Iteration 76 Epoch 1 loss 701.3897210715564\n",
      "Iteration 77 Epoch 1 loss 848.5563035838741\n",
      "Iteration 78 Epoch 1 loss 658.9977908767692\n",
      "Iteration 79 Epoch 1 loss 827.8766066613501\n",
      "Iteration 80 Epoch 1 loss 771.755834959128\n",
      "Iteration 81 Epoch 1 loss 633.9084672082943\n",
      "Iteration 82 Epoch 1 loss 774.2790472295495\n",
      "Iteration 83 Epoch 1 loss 809.3632676578172\n",
      "Iteration 84 Epoch 1 loss 711.6430384265177\n",
      "Iteration 85 Epoch 1 loss 720.4807086888727\n",
      "Iteration 86 Epoch 1 loss 591.1576965548471\n",
      "Iteration 87 Epoch 1 loss 722.4976344065146\n",
      "Iteration 88 Epoch 1 loss 614.2878343560918\n",
      "Iteration 89 Epoch 1 loss 637.4861417117143\n",
      "Iteration 90 Epoch 1 loss 819.9715396041072\n",
      "Iteration 91 Epoch 1 loss 713.1636417374136\n",
      "Iteration 92 Epoch 1 loss 686.8379987109664\n",
      "Iteration 93 Epoch 1 loss 585.8502996093198\n",
      "Iteration 94 Epoch 1 loss 681.6253372107087\n",
      "Iteration 95 Epoch 1 loss 583.1232848764165\n",
      "Iteration 96 Epoch 1 loss 884.9846289897832\n",
      "Iteration 97 Epoch 1 loss 619.8022248666686\n",
      "Iteration 98 Epoch 1 loss 720.5251158399614\n",
      "Iteration 99 Epoch 1 loss 714.2335845258497\n",
      "Iteration 100 Epoch 1 loss 645.6048128338367\n",
      "Iteration 101 Epoch 1 loss 837.8178675701306\n",
      "Iteration 102 Epoch 1 loss 721.6858697502064\n",
      "Iteration 103 Epoch 1 loss 795.1457720685667\n",
      "Iteration 104 Epoch 1 loss 711.8596862789382\n",
      "Iteration 105 Epoch 1 loss 757.1822546477719\n",
      "Iteration 106 Epoch 1 loss 691.6215689213352\n",
      "Iteration 107 Epoch 1 loss 708.4692101116722\n",
      "Iteration 108 Epoch 1 loss 684.5018483097405\n",
      "Iteration 109 Epoch 1 loss 781.0082121245014\n",
      "Iteration 110 Epoch 1 loss 719.5192477066993\n",
      "Iteration 111 Epoch 1 loss 740.6843999668749\n",
      "Iteration 112 Epoch 1 loss 667.0301719871412\n",
      "Iteration 113 Epoch 1 loss 622.5369801982113\n",
      "Iteration 114 Epoch 1 loss 651.0351807178349\n",
      "Iteration 115 Epoch 2 loss 912.3917940447141\n",
      "Iteration 116 Epoch 2 loss 672.2285663533967\n",
      "Iteration 117 Epoch 2 loss 718.1920014904603\n",
      "Iteration 118 Epoch 2 loss 561.6024112034913\n",
      "Iteration 119 Epoch 2 loss 549.436061773546\n",
      "Iteration 120 Epoch 2 loss 726.0727642847389\n",
      "Iteration 121 Epoch 2 loss 555.9121077441097\n",
      "Iteration 122 Epoch 2 loss 590.8163631914376\n",
      "Iteration 123 Epoch 2 loss 706.6654641437952\n",
      "Iteration 124 Epoch 2 loss 742.5608955498901\n",
      "Iteration 125 Epoch 2 loss 664.8164772374726\n",
      "Iteration 126 Epoch 2 loss 707.8083642735077\n",
      "Iteration 127 Epoch 2 loss 643.6107590394223\n",
      "Iteration 128 Epoch 2 loss 617.0000684230165\n",
      "Iteration 129 Epoch 2 loss 727.4244704827037\n",
      "Iteration 130 Epoch 2 loss 712.8247285878383\n",
      "Iteration 131 Epoch 2 loss 814.6086795604024\n",
      "Iteration 132 Epoch 2 loss 762.5847237932076\n",
      "Iteration 133 Epoch 2 loss 687.5891002043687\n",
      "Iteration 134 Epoch 2 loss 821.0788145970924\n",
      "Iteration 135 Epoch 2 loss 609.9224363762685\n",
      "Iteration 136 Epoch 2 loss 779.7470025139463\n",
      "Iteration 137 Epoch 2 loss 740.7563439479794\n",
      "Iteration 138 Epoch 2 loss 595.3062289632601\n",
      "Iteration 139 Epoch 2 loss 731.7468173083422\n",
      "Iteration 140 Epoch 2 loss 754.1105654219341\n",
      "Iteration 141 Epoch 2 loss 668.0456419631238\n",
      "Iteration 142 Epoch 2 loss 667.7997721200659\n",
      "Iteration 143 Epoch 2 loss 565.702748488915\n",
      "Iteration 144 Epoch 2 loss 671.6153921284887\n",
      "Iteration 145 Epoch 2 loss 564.1931186242555\n",
      "Iteration 146 Epoch 2 loss 607.813514384026\n",
      "Iteration 147 Epoch 2 loss 770.5993079905138\n",
      "Iteration 148 Epoch 2 loss 686.4402625799526\n",
      "Iteration 149 Epoch 2 loss 653.5680787093136\n",
      "Iteration 150 Epoch 2 loss 540.8342954777421\n",
      "Iteration 151 Epoch 2 loss 650.052628897198\n",
      "Iteration 152 Epoch 2 loss 555.4512652689041\n",
      "Iteration 153 Epoch 2 loss 838.1456562283744\n",
      "Iteration 154 Epoch 2 loss 571.357869628858\n",
      "Iteration 155 Epoch 2 loss 680.7947844541739\n",
      "Iteration 156 Epoch 2 loss 665.2263069858017\n",
      "Iteration 157 Epoch 2 loss 599.7981570460748\n",
      "Iteration 158 Epoch 2 loss 798.8466097914492\n",
      "Iteration 159 Epoch 2 loss 705.6883306548475\n",
      "Iteration 160 Epoch 2 loss 747.504922287172\n",
      "Iteration 161 Epoch 2 loss 677.9494033744521\n",
      "Iteration 162 Epoch 2 loss 704.1957104019796\n",
      "Iteration 163 Epoch 2 loss 638.9763486371769\n",
      "Iteration 164 Epoch 2 loss 674.1421037903432\n",
      "Iteration 165 Epoch 2 loss 656.1156707570043\n",
      "Iteration 166 Epoch 2 loss 735.1783089245885\n",
      "Iteration 167 Epoch 2 loss 680.0573115297651\n",
      "Iteration 168 Epoch 2 loss 687.5575626356582\n",
      "Iteration 169 Epoch 2 loss 640.5093701219471\n",
      "Iteration 170 Epoch 2 loss 605.4421880963537\n",
      "Iteration 171 Epoch 2 loss 607.9721519589633\n",
      "Iteration 172 Epoch 3 loss 877.3064658085334\n",
      "Iteration 173 Epoch 3 loss 630.1685966084492\n",
      "Iteration 174 Epoch 3 loss 677.7484998431001\n",
      "Iteration 175 Epoch 3 loss 548.9090626433663\n",
      "Iteration 176 Epoch 3 loss 516.2940300559745\n",
      "Iteration 177 Epoch 3 loss 669.7809354876142\n",
      "Iteration 178 Epoch 3 loss 530.3158163027476\n",
      "Iteration 179 Epoch 3 loss 553.8722019664192\n",
      "Iteration 180 Epoch 3 loss 678.8083058288433\n",
      "Iteration 181 Epoch 3 loss 724.0862278770006\n",
      "Iteration 182 Epoch 3 loss 639.6903927799511\n",
      "Iteration 183 Epoch 3 loss 664.8051740835404\n",
      "Iteration 184 Epoch 3 loss 607.0559319383053\n",
      "Iteration 185 Epoch 3 loss 596.4826895710861\n",
      "Iteration 186 Epoch 3 loss 700.8950752229838\n",
      "Iteration 187 Epoch 3 loss 694.4971034357123\n",
      "Iteration 188 Epoch 3 loss 750.7126311893618\n",
      "Iteration 189 Epoch 3 loss 740.7741490739546\n",
      "Iteration 190 Epoch 3 loss 679.3113133865221\n",
      "Iteration 191 Epoch 3 loss 801.9293807975268\n",
      "Iteration 192 Epoch 3 loss 571.9368755418556\n",
      "Iteration 193 Epoch 3 loss 742.9827388446627\n",
      "Iteration 194 Epoch 3 loss 716.5725766027706\n",
      "Iteration 195 Epoch 3 loss 566.4801180524001\n",
      "Iteration 196 Epoch 3 loss 700.5011892260837\n",
      "Iteration 197 Epoch 3 loss 711.95664268895\n",
      "Iteration 198 Epoch 3 loss 634.8343971653359\n",
      "Iteration 199 Epoch 3 loss 629.2738173665568\n",
      "Iteration 200 Epoch 3 loss 546.3594745240462\n",
      "Iteration 201 Epoch 3 loss 632.3928752833066\n",
      "Iteration 202 Epoch 3 loss 525.9522887547944\n",
      "Iteration 203 Epoch 3 loss 585.2922065765857\n",
      "Iteration 204 Epoch 3 loss 733.1626204106842\n",
      "Iteration 205 Epoch 3 loss 665.538698759865\n",
      "Iteration 206 Epoch 3 loss 628.4068841167558\n",
      "Iteration 207 Epoch 3 loss 505.65633312364395\n",
      "Iteration 208 Epoch 3 loss 623.8302734959451\n",
      "Iteration 209 Epoch 3 loss 533.9078696456838\n",
      "Iteration 210 Epoch 3 loss 804.7692581381451\n",
      "Iteration 211 Epoch 3 loss 533.2681155275366\n",
      "Iteration 212 Epoch 3 loss 648.8618955761585\n",
      "Iteration 213 Epoch 3 loss 627.0540053889234\n",
      "Iteration 214 Epoch 3 loss 562.9506981774201\n",
      "Iteration 215 Epoch 3 loss 770.0079847896512\n",
      "Iteration 216 Epoch 3 loss 694.316774805951\n",
      "Iteration 217 Epoch 3 loss 711.7874667014895\n",
      "Iteration 218 Epoch 3 loss 652.1763534729788\n",
      "Iteration 219 Epoch 3 loss 663.0529144209517\n",
      "Iteration 220 Epoch 3 loss 599.518441536957\n",
      "Iteration 221 Epoch 3 loss 647.7726429426061\n",
      "Iteration 222 Epoch 3 loss 633.681967200874\n",
      "Iteration 223 Epoch 3 loss 699.7837402611887\n",
      "Iteration 224 Epoch 3 loss 649.7566068659795\n",
      "Iteration 225 Epoch 3 loss 647.4836463338657\n",
      "Iteration 226 Epoch 3 loss 617.9476181442478\n",
      "Iteration 227 Epoch 3 loss 592.3287623601902\n",
      "Iteration 228 Epoch 3 loss 574.3086751574956\n",
      "Iteration 229 Epoch 4 loss 847.634180330626\n",
      "Iteration 230 Epoch 4 loss 597.2715138760263\n",
      "Iteration 231 Epoch 4 loss 646.9223404978997\n",
      "Iteration 232 Epoch 4 loss 541.3147836511287\n",
      "Iteration 233 Epoch 4 loss 488.5235491630196\n",
      "Iteration 234 Epoch 4 loss 623.7946008257613\n",
      "Iteration 235 Epoch 4 loss 509.0130101652047\n",
      "Iteration 236 Epoch 4 loss 522.2972999996913\n",
      "Iteration 237 Epoch 4 loss 657.6590091610705\n",
      "Iteration 238 Epoch 4 loss 711.023105861968\n",
      "Iteration 239 Epoch 4 loss 618.1383274264753\n",
      "Iteration 240 Epoch 4 loss 628.9632492238445\n",
      "Iteration 241 Epoch 4 loss 576.9442771482031\n",
      "Iteration 242 Epoch 4 loss 579.9155454712551\n",
      "Iteration 243 Epoch 4 loss 680.5189776320583\n",
      "Iteration 244 Epoch 4 loss 679.8566213034115\n",
      "Iteration 245 Epoch 4 loss 702.9121429580852\n",
      "Iteration 246 Epoch 4 loss 726.5099032723252\n",
      "Iteration 247 Epoch 4 loss 675.1354451881466\n",
      "Iteration 248 Epoch 4 loss 787.5824641128349\n",
      "Iteration 249 Epoch 4 loss 540.2701924092719\n",
      "Iteration 250 Epoch 4 loss 713.0751477850745\n",
      "Iteration 251 Epoch 4 loss 696.9641915401941\n",
      "Iteration 252 Epoch 4 loss 544.3407333173429\n",
      "Iteration 253 Epoch 4 loss 676.8385350110879\n",
      "Iteration 254 Epoch 4 loss 677.6622895017948\n",
      "Iteration 255 Epoch 4 loss 608.1917773919711\n",
      "Iteration 256 Epoch 4 loss 599.4901452038092\n",
      "Iteration 257 Epoch 4 loss 531.7083907897487\n",
      "Iteration 258 Epoch 4 loss 600.8536654181542\n",
      "Iteration 259 Epoch 4 loss 495.16505779283705\n",
      "Iteration 260 Epoch 4 loss 567.5760541788304\n",
      "Iteration 261 Epoch 4 loss 702.9552024363294\n",
      "Iteration 262 Epoch 4 loss 649.089238258791\n",
      "Iteration 263 Epoch 4 loss 608.7078474520476\n",
      "Iteration 264 Epoch 4 loss 476.46336893734406\n",
      "Iteration 265 Epoch 4 loss 600.9418139342448\n",
      "Iteration 266 Epoch 4 loss 516.5994147228156\n",
      "Iteration 267 Epoch 4 loss 780.0895333709095\n",
      "Iteration 268 Epoch 4 loss 501.7905495950785\n",
      "Iteration 269 Epoch 4 loss 622.642335241952\n",
      "Iteration 270 Epoch 4 loss 595.7788887306219\n",
      "Iteration 271 Epoch 4 loss 531.8552258201297\n",
      "Iteration 272 Epoch 4 loss 748.0266302532459\n",
      "Iteration 273 Epoch 4 loss 686.3451496462068\n",
      "Iteration 274 Epoch 4 loss 683.6880075810843\n",
      "Iteration 275 Epoch 4 loss 631.6990422831988\n",
      "Iteration 276 Epoch 4 loss 629.3788541243657\n",
      "Iteration 277 Epoch 4 loss 567.9761623499128\n",
      "Iteration 278 Epoch 4 loss 626.7057104136267\n",
      "Iteration 279 Epoch 4 loss 615.4828783555236\n",
      "Iteration 280 Epoch 4 loss 671.006741463003\n",
      "Iteration 281 Epoch 4 loss 625.0697079931174\n",
      "Iteration 282 Epoch 4 loss 615.7924772800809\n",
      "Iteration 283 Epoch 4 loss 598.121428193375\n",
      "Iteration 284 Epoch 4 loss 582.31270870027\n",
      "Iteration 285 Epoch 4 loss 546.7191061381119\n",
      "Iteration 1 Epoch 0 loss 594.962929015296\n",
      "Iteration 2 Epoch 0 loss 520.7369738561546\n",
      "Iteration 3 Epoch 0 loss 694.6955732654081\n",
      "Iteration 4 Epoch 0 loss 596.361194916863\n",
      "Iteration 5 Epoch 0 loss 681.8468845427352\n",
      "Iteration 6 Epoch 0 loss 524.6064801431525\n",
      "Iteration 7 Epoch 0 loss 421.04878246079033\n",
      "Iteration 8 Epoch 0 loss 628.2184176385654\n",
      "Iteration 9 Epoch 0 loss 636.5844384997945\n",
      "Iteration 10 Epoch 0 loss 630.7421974823893\n",
      "Iteration 11 Epoch 0 loss 538.2713586481427\n",
      "Iteration 12 Epoch 0 loss 538.8670001858114\n",
      "Iteration 13 Epoch 0 loss 483.4127070888173\n",
      "Iteration 14 Epoch 0 loss 671.8668193073925\n",
      "Iteration 15 Epoch 0 loss 890.517300822467\n",
      "Iteration 16 Epoch 0 loss 579.9260609265776\n",
      "Iteration 17 Epoch 0 loss 648.9191130541993\n",
      "Iteration 18 Epoch 0 loss 545.1154281711129\n",
      "Iteration 19 Epoch 0 loss 637.2390290925316\n",
      "Iteration 20 Epoch 0 loss 516.3213510126934\n",
      "Iteration 21 Epoch 0 loss 742.702819070367\n",
      "Iteration 22 Epoch 0 loss 712.8033385837076\n",
      "Iteration 23 Epoch 0 loss 589.7983006126784\n",
      "Iteration 24 Epoch 0 loss 568.7074402926697\n",
      "Iteration 25 Epoch 0 loss 491.5111837028072\n",
      "Iteration 26 Epoch 0 loss 598.5840406083569\n",
      "Iteration 27 Epoch 0 loss 592.1160717130361\n",
      "Iteration 28 Epoch 0 loss 560.7660807215076\n",
      "Iteration 29 Epoch 0 loss 653.3435664380407\n",
      "Iteration 30 Epoch 0 loss 579.860987839902\n",
      "Iteration 31 Epoch 0 loss 497.2434885085611\n",
      "Iteration 32 Epoch 0 loss 497.90952973587105\n",
      "Iteration 33 Epoch 0 loss 679.7253834056577\n",
      "Iteration 34 Epoch 0 loss 748.5031702898378\n",
      "Iteration 35 Epoch 0 loss 560.2603946408279\n",
      "Iteration 36 Epoch 0 loss 658.552065789735\n",
      "Iteration 37 Epoch 0 loss 551.1661286876633\n",
      "Iteration 38 Epoch 0 loss 646.8390611589391\n",
      "Iteration 39 Epoch 0 loss 702.0146402984288\n",
      "Iteration 40 Epoch 0 loss 546.4973246852969\n",
      "Iteration 41 Epoch 0 loss 487.56976133955135\n",
      "Iteration 42 Epoch 0 loss 760.7923165740597\n",
      "Iteration 43 Epoch 0 loss 748.9040642171275\n",
      "Iteration 44 Epoch 0 loss 712.9467454954498\n",
      "Iteration 45 Epoch 0 loss 549.763705998866\n",
      "Iteration 46 Epoch 0 loss 689.7335100899808\n",
      "Iteration 47 Epoch 0 loss 535.3079731890363\n",
      "Iteration 48 Epoch 0 loss 732.2389396346022\n",
      "Iteration 49 Epoch 0 loss 659.7803703885791\n",
      "Iteration 50 Epoch 0 loss 485.7278294593923\n",
      "Iteration 51 Epoch 0 loss 638.0904484362402\n",
      "Iteration 52 Epoch 0 loss 668.913457368556\n",
      "Iteration 53 Epoch 0 loss 704.4099855059205\n",
      "Iteration 54 Epoch 0 loss 689.5684804138384\n",
      "Iteration 55 Epoch 0 loss 480.3840632098436\n",
      "Iteration 56 Epoch 0 loss 618.5778710013528\n",
      "Iteration 57 Epoch 0 loss 444.1399054302087\n",
      "Iteration 58 Epoch 1 loss 592.1912419528094\n",
      "Iteration 59 Epoch 1 loss 512.3212319826615\n",
      "Iteration 60 Epoch 1 loss 693.3138798354516\n",
      "Iteration 61 Epoch 1 loss 594.2658431593348\n",
      "Iteration 62 Epoch 1 loss 676.9001957162393\n",
      "Iteration 63 Epoch 1 loss 524.5524662190818\n",
      "Iteration 64 Epoch 1 loss 419.7485643809782\n",
      "Iteration 65 Epoch 1 loss 624.6703380686458\n",
      "Iteration 66 Epoch 1 loss 629.3596784748422\n",
      "Iteration 67 Epoch 1 loss 628.3788191576706\n",
      "Iteration 68 Epoch 1 loss 534.7281473763145\n",
      "Iteration 69 Epoch 1 loss 543.854583999138\n",
      "Iteration 70 Epoch 1 loss 479.41952043746153\n",
      "Iteration 71 Epoch 1 loss 673.7755741726129\n",
      "Iteration 72 Epoch 1 loss 886.0895802129784\n",
      "Iteration 73 Epoch 1 loss 581.1136822399515\n",
      "Iteration 74 Epoch 1 loss 645.7311032307791\n",
      "Iteration 75 Epoch 1 loss 540.8459445349137\n",
      "Iteration 76 Epoch 1 loss 637.868622298023\n",
      "Iteration 77 Epoch 1 loss 514.2415936980065\n",
      "Iteration 78 Epoch 1 loss 739.6949339412873\n",
      "Iteration 79 Epoch 1 loss 713.5681128386185\n",
      "Iteration 80 Epoch 1 loss 584.8601530667991\n",
      "Iteration 81 Epoch 1 loss 561.3161221151985\n",
      "Iteration 82 Epoch 1 loss 490.6686167577143\n",
      "Iteration 83 Epoch 1 loss 595.3333411030271\n",
      "Iteration 84 Epoch 1 loss 588.441532434652\n",
      "Iteration 85 Epoch 1 loss 556.4344998920711\n",
      "Iteration 86 Epoch 1 loss 650.6451875270718\n",
      "Iteration 87 Epoch 1 loss 573.8514333957244\n",
      "Iteration 88 Epoch 1 loss 493.4269273217805\n",
      "Iteration 89 Epoch 1 loss 495.55178805994524\n",
      "Iteration 90 Epoch 1 loss 678.0319685459314\n",
      "Iteration 91 Epoch 1 loss 745.3241117229406\n",
      "Iteration 92 Epoch 1 loss 555.9237936590766\n",
      "Iteration 93 Epoch 1 loss 657.0164120509268\n",
      "Iteration 94 Epoch 1 loss 548.9921957350367\n",
      "Iteration 95 Epoch 1 loss 644.7811830717634\n",
      "Iteration 96 Epoch 1 loss 700.0867399706984\n",
      "Iteration 97 Epoch 1 loss 545.3105135616005\n",
      "Iteration 98 Epoch 1 loss 485.1482147714686\n",
      "Iteration 99 Epoch 1 loss 758.2185254043951\n",
      "Iteration 100 Epoch 1 loss 747.1103140367655\n",
      "Iteration 101 Epoch 1 loss 710.0699604734273\n",
      "Iteration 102 Epoch 1 loss 548.471939877304\n",
      "Iteration 103 Epoch 1 loss 688.4450921257217\n",
      "Iteration 104 Epoch 1 loss 534.5355637199146\n",
      "Iteration 105 Epoch 1 loss 731.6368185385568\n",
      "Iteration 106 Epoch 1 loss 658.1802458645984\n",
      "Iteration 107 Epoch 1 loss 481.9161215261621\n",
      "Iteration 108 Epoch 1 loss 637.055334394286\n",
      "Iteration 109 Epoch 1 loss 667.0462823890326\n",
      "Iteration 110 Epoch 1 loss 701.7218440903393\n",
      "Iteration 111 Epoch 1 loss 686.707881236816\n",
      "Iteration 112 Epoch 1 loss 479.0545447105967\n",
      "Iteration 113 Epoch 1 loss 617.7138267116934\n",
      "Iteration 114 Epoch 1 loss 441.01690341879066\n",
      "Iteration 115 Epoch 2 loss 590.8205864181976\n",
      "Iteration 116 Epoch 2 loss 509.15248703376955\n",
      "Iteration 117 Epoch 2 loss 691.0353585071083\n",
      "Iteration 118 Epoch 2 loss 592.7444050307192\n",
      "Iteration 119 Epoch 2 loss 674.5479621705705\n",
      "Iteration 120 Epoch 2 loss 523.5189049232968\n",
      "Iteration 121 Epoch 2 loss 418.4292424361764\n",
      "Iteration 122 Epoch 2 loss 623.3078471164404\n",
      "Iteration 123 Epoch 2 loss 626.7945448601708\n",
      "Iteration 124 Epoch 2 loss 626.2969019866625\n",
      "Iteration 125 Epoch 2 loss 532.8814084949238\n",
      "Iteration 126 Epoch 2 loss 543.1760931729939\n",
      "Iteration 127 Epoch 2 loss 477.77719103220863\n",
      "Iteration 128 Epoch 2 loss 672.5742817688694\n",
      "Iteration 129 Epoch 2 loss 884.5157117066863\n",
      "Iteration 130 Epoch 2 loss 580.3260651314389\n",
      "Iteration 131 Epoch 2 loss 642.4348108452474\n",
      "Iteration 132 Epoch 2 loss 538.8708619945885\n",
      "Iteration 133 Epoch 2 loss 636.7694635521472\n",
      "Iteration 134 Epoch 2 loss 512.2268269937558\n",
      "Iteration 135 Epoch 2 loss 738.0794514119495\n",
      "Iteration 136 Epoch 2 loss 712.4076149047984\n",
      "Iteration 137 Epoch 2 loss 581.4722631412172\n",
      "Iteration 138 Epoch 2 loss 557.6924182770923\n",
      "Iteration 139 Epoch 2 loss 489.1575941741277\n",
      "Iteration 140 Epoch 2 loss 593.7159737601946\n",
      "Iteration 141 Epoch 2 loss 585.5011461836809\n",
      "Iteration 142 Epoch 2 loss 554.824356632111\n",
      "Iteration 143 Epoch 2 loss 647.3397789030357\n",
      "Iteration 144 Epoch 2 loss 571.7334298877606\n",
      "Iteration 145 Epoch 2 loss 491.33327272703923\n",
      "Iteration 146 Epoch 2 loss 492.7050002061695\n",
      "Iteration 147 Epoch 2 loss 675.743646509575\n",
      "Iteration 148 Epoch 2 loss 742.8903288467598\n",
      "Iteration 149 Epoch 2 loss 553.2774610701283\n",
      "Iteration 150 Epoch 2 loss 655.0251253395306\n",
      "Iteration 151 Epoch 2 loss 546.9350208965038\n",
      "Iteration 152 Epoch 2 loss 642.8657895953364\n",
      "Iteration 153 Epoch 2 loss 698.046011817421\n",
      "Iteration 154 Epoch 2 loss 543.7540709964375\n",
      "Iteration 155 Epoch 2 loss 483.82377846345827\n",
      "Iteration 156 Epoch 2 loss 756.776316760234\n",
      "Iteration 157 Epoch 2 loss 745.3329283846293\n",
      "Iteration 158 Epoch 2 loss 708.6714879072003\n",
      "Iteration 159 Epoch 2 loss 546.867308283277\n",
      "Iteration 160 Epoch 2 loss 686.5886857529592\n",
      "Iteration 161 Epoch 2 loss 532.9740835795466\n",
      "Iteration 162 Epoch 2 loss 729.633144006689\n",
      "Iteration 163 Epoch 2 loss 656.4106553119414\n",
      "Iteration 164 Epoch 2 loss 479.6352949199018\n",
      "Iteration 165 Epoch 2 loss 635.2139472458172\n",
      "Iteration 166 Epoch 2 loss 664.5090190587152\n",
      "Iteration 167 Epoch 2 loss 700.1151719053394\n",
      "Iteration 168 Epoch 2 loss 684.6759439298935\n",
      "Iteration 169 Epoch 2 loss 477.19675976062655\n",
      "Iteration 170 Epoch 2 loss 616.1099341216488\n",
      "Iteration 171 Epoch 2 loss 438.91581280642464\n",
      "Iteration 172 Epoch 3 loss 589.4306690139595\n",
      "Iteration 173 Epoch 3 loss 506.90891952834255\n",
      "Iteration 174 Epoch 3 loss 688.3999626702006\n",
      "Iteration 175 Epoch 3 loss 591.1043942425455\n",
      "Iteration 176 Epoch 3 loss 672.6092986659073\n",
      "Iteration 177 Epoch 3 loss 522.0008437996013\n",
      "Iteration 178 Epoch 3 loss 416.83325701832786\n",
      "Iteration 179 Epoch 3 loss 622.3213814059112\n",
      "Iteration 180 Epoch 3 loss 625.1632288615241\n",
      "Iteration 181 Epoch 3 loss 624.1353343915048\n",
      "Iteration 182 Epoch 3 loss 531.3521075740325\n",
      "Iteration 183 Epoch 3 loss 541.1408187679317\n",
      "Iteration 184 Epoch 3 loss 476.55736160799336\n",
      "Iteration 185 Epoch 3 loss 670.6281710567094\n",
      "Iteration 186 Epoch 3 loss 883.7195675494622\n",
      "Iteration 187 Epoch 3 loss 579.0233132366872\n",
      "Iteration 188 Epoch 3 loss 639.0928750606635\n",
      "Iteration 189 Epoch 3 loss 537.2598155595838\n",
      "Iteration 190 Epoch 3 loss 635.2920017907034\n",
      "Iteration 191 Epoch 3 loss 510.0824298823068\n",
      "Iteration 192 Epoch 3 loss 736.7670573809839\n",
      "Iteration 193 Epoch 3 loss 710.7979685101164\n",
      "Iteration 194 Epoch 3 loss 578.3620913498138\n",
      "Iteration 195 Epoch 3 loss 554.8391474428176\n",
      "Iteration 196 Epoch 3 loss 487.4980398948024\n",
      "Iteration 197 Epoch 3 loss 592.4156544879451\n",
      "Iteration 198 Epoch 3 loss 582.6599869257491\n",
      "Iteration 199 Epoch 3 loss 553.8950512580147\n",
      "Iteration 200 Epoch 3 loss 643.7864061409769\n",
      "Iteration 201 Epoch 3 loss 570.4686179289985\n",
      "Iteration 202 Epoch 3 loss 489.5974059918974\n",
      "Iteration 203 Epoch 3 loss 489.653251376571\n",
      "Iteration 204 Epoch 3 loss 673.3934676886232\n",
      "Iteration 205 Epoch 3 loss 740.6599984814942\n",
      "Iteration 206 Epoch 3 loss 550.8785919627032\n",
      "Iteration 207 Epoch 3 loss 652.9904235909661\n",
      "Iteration 208 Epoch 3 loss 544.8676857824591\n",
      "Iteration 209 Epoch 3 loss 640.9866810392314\n",
      "Iteration 210 Epoch 3 loss 695.9938936164206\n",
      "Iteration 211 Epoch 3 loss 542.1908576714411\n",
      "Iteration 212 Epoch 3 loss 482.7136611339008\n",
      "Iteration 213 Epoch 3 loss 755.6554644058934\n",
      "Iteration 214 Epoch 3 loss 743.5851744545331\n",
      "Iteration 215 Epoch 3 loss 707.6503089587152\n",
      "Iteration 216 Epoch 3 loss 545.1494685228978\n",
      "Iteration 217 Epoch 3 loss 684.7477855510244\n",
      "Iteration 218 Epoch 3 loss 531.271954312233\n",
      "Iteration 219 Epoch 3 loss 727.3639018340841\n",
      "Iteration 220 Epoch 3 loss 654.7026853958469\n",
      "Iteration 221 Epoch 3 loss 477.69673635698115\n",
      "Iteration 222 Epoch 3 loss 633.2842995333749\n",
      "Iteration 223 Epoch 3 loss 661.7199595934927\n",
      "Iteration 224 Epoch 3 loss 698.7959781954418\n",
      "Iteration 225 Epoch 3 loss 682.8250998388769\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m ts_fnn\u001b[38;5;241m.\u001b[39minit_sigma_parameters([[\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m], [\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m], [\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m]])\n\u001b[0;32m      9\u001b[0m ts_fnn\u001b[38;5;241m.\u001b[39mfit(train_X, train_Y, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, gradient_accumulation_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mts_fnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_accumulation_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# ts_fnn.fit(train_X, train_Y, epoch=10, learning_rate=0.1, gradient_descent_strategy='full')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\Documents\\programming\\medical-fuzzy-rules-extraction\\takagi_sugeno_fnn.py:85\u001b[0m, in \u001b[0;36mTS_FNN.fit\u001b[1;34m(self, X, Y, gradient_descent_strategy, gradient_accumulation_step, epoch, learning_rate, L2_reg, noise_variance)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m loss \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, e, loss(params, t)))\n\u001b[0;32m     84\u001b[0m             i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 85\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m gradient_descent_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     87\u001b[0m     X \u001b[38;5;241m=\u001b[39m [X[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\misc\\optimizers.py:28\u001b[0m, in \u001b[0;36munflatten_optimizer.<locals>._optimize\u001b[1;34m(grad, x0, callback, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     _callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten(\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_x0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\misc\\optimizers.py:38\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(grad, x, callback, num_iters, step_size, mass)\u001b[0m\n\u001b[0;32m     36\u001b[0m velocity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(x))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[1;32m---> 38\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback: callback(x, i, g)\n\u001b[0;32m     40\u001b[0m     velocity \u001b[38;5;241m=\u001b[39m mass \u001b[38;5;241m*\u001b[39m velocity \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m mass) \u001b[38;5;241m*\u001b[39m g\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\misc\\optimizers.py:23\u001b[0m, in \u001b[0;36munflatten_optimizer.<locals>._optimize.<locals>.<lambda>\u001b[1;34m(x, i)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(optimize)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize\u001b[39m(grad, x0, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     _x0, unflatten \u001b[38;5;241m=\u001b[39m flatten(x0)\n\u001b[1;32m---> 23\u001b[0m     _grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, i: flatten(\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m     25\u001b[0m         _callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, i, g: callback(unflatten(x), i, unflatten(g))\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\differential_operators.py:32\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[1;34m(g)\u001b[0m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\core.py:23\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(g, end_node)\u001b[0m\n\u001b[0;32m     21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mvjp(outgrad[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[1;32m---> 23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m \u001b[43madd_outgrads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mingrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outgrad[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\core.py:176\u001b[0m, in \u001b[0;36madd_outgrads\u001b[1;34m(prev_g_flagged, g)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse:\n\u001b[1;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparse_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m g, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\core.py:186\u001b[0m, in \u001b[0;36msparse_add\u001b[1;34m(vs, x_prev, x_new)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;129m@primitive\u001b[39m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msparse_add\u001b[39m(vs, x_prev, x_new):\n\u001b[0;32m    185\u001b[0m     x_prev \u001b[38;5;241m=\u001b[39m x_prev \u001b[38;5;28;01mif\u001b[39;00m x_prev \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m vs\u001b[38;5;241m.\u001b[39mzeros()\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmut_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_prev\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikip\\anaconda3\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:698\u001b[0m, in \u001b[0;36muntake.<locals>.mut_add\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmut_add\u001b[39m(A):\n\u001b[1;32m--> 698\u001b[0m     \u001b[43monp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m A\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorized_train_data = normalize(vectorize(train_data))\n",
    "train_X = np.array([data[0:-1] for data in vectorized_train_data])\n",
    "train_Y = np.array([data[-1] for data in vectorized_train_data])\n",
    "\n",
    "ts_fnn = TS_FNN([2, 2, 2], [[0, 0, 0], [1, 1, 1]])\n",
    "ts_fnn.init_mu_parameters([[0.48, 0.72], [0., 1.], [0.68, 0.39]])\n",
    "ts_fnn.init_sigma_parameters([[1., 1.], [1., 1.], [1., 1.]])\n",
    "\n",
    "ts_fnn.fit(train_X, train_Y, epochs=5, learning_rate=0.0001, gradient_accumulation_step=128)\n",
    "ts_fnn.fit(train_X, train_Y, epochs=5, learning_rate=0.00001, gradient_accumulation_step=128)\n",
    "# ts_fnn.fit(train_X, train_Y, epoch=10, learning_rate=0.1, gradient_descent_strategy='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TS_FNN.fit() got an unexpected keyword argument 'loss_f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mts_fnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_likelihood\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_accumulation_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TS_FNN.fit() got an unexpected keyword argument 'loss_f'"
     ]
    }
   ],
   "source": [
    "ts_fnn.fit(train_X, train_Y, loss_f='log_likelihood', epoch=5, learning_rate=0.0001, gradient_accumulation_step=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.44958483,  0.72400186],\n",
       "        [-0.19724562,  1.14474241],\n",
       "        [ 0.55080861,  0.26167913]]),\n",
       " array([[1.00001861, 0.99959421],\n",
       "        [0.73616809, 0.83561778],\n",
       "        [1.01847604, 1.01473264]]),\n",
       " array([0.68408209, 0.10076171]),\n",
       " [array([0.23789712, 0.36961834, 0.31571193]),\n",
       "  array([ 0.00721071, -0.06961426,  0.75603679])])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_fnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 8.87619465e-02, -3.30649061e-03],\n",
       "        [-1.00568472e+00, -1.27118039e+01],\n",
       "        [ 5.20093829e-01, -1.06215385e-02]]),\n",
       " array([[-2.23100973e-02, -5.35383055e-04],\n",
       "        [-3.69253096e-01,  3.19577539e+01],\n",
       "        [-3.14632086e-01, -1.73948450e-02]]),\n",
       " array([-97.62297471,  -2.67833648]),\n",
       " [array([-4.96253447e+01,  9.91543850e-03, -2.24870616e+01]),\n",
       "  array([ 8.44485093,  1.79892799, 19.43315353])])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import autograd.scipy.stats.norm as norm\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "\n",
    "def loss(parameters, t):\n",
    "    return -logprob(parameters, train_X[:50], train_Y[:50])\n",
    "\n",
    "def logprob(parameters, X, Y, noise_scale=0.1):\n",
    "    Y_bar = np.array([ts_fnn.forward(parameters, x) for x in X])\n",
    "    return np.sum(norm.logpdf(Y_bar, Y, noise_scale))\n",
    "\n",
    "grad(loss)(ts_fnn.parameters, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing import r_squared_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5619945948307223"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_test_data = normalize(vectorize(test_data))\n",
    "test_X = np.array([data[0:-1] for data in vectorized_test_data])\n",
    "test_Y = np.array([data[-1] for data in vectorized_test_data])\n",
    "prediction_fun = lambda x: ts_fnn.predict(x)\n",
    "\n",
    "r_squared_test(prediction_fun, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisson with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5123566227802898"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(train_X, train_Y)\n",
    "\n",
    "r_squared_test(lambda x: reg.predict([x])[0], test_X, test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
